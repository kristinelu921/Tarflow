{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kristinelu921/Tarflow/blob/main/tarflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "kcOM5nHxO3Di",
        "outputId": "e8afe52e-eb18-4e73-92bc-a03da63cda53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaynelu921\u001b[0m (\u001b[33mkaynelu921-massachusetts-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "!pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTrDTfIZPMIt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "DEKRdH5N-uze"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    dataset = \"mnist\"\n",
        "    img_size = 28\n",
        "    patch_size = 4\n",
        "    n_channels = 1\n",
        "    dataset_size = 60000\n",
        "\n",
        "\n",
        "    #patch embed\n",
        "    num_patches = (img_size//patch_size)**2\n",
        "    d_patch = n_channels * patch_size * patch_size\n",
        "\n",
        "    #PE\n",
        "    max_seq_length = num_patches + 1\n",
        "\n",
        "    #ViT\n",
        "    d_model: int = 64\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    init_range: float = 0.02\n",
        "    n_layers = 2 #number of transformer layers\n",
        "    dropout = 0.1\n",
        "    r_mlp = 2 #scales size of intermed. layer\n",
        "\n",
        "    #AttentionHead\n",
        "    n_heads = 2\n",
        "    d_head = d_model//n_heads\n",
        "\n",
        "    #Training\n",
        "    epochs = 5\n",
        "    mask = True\n",
        "    has_scheduler = True\n",
        "    batch_size = 128\n",
        "    eta_min_scale = 0.0001\n",
        "\n",
        "    #learning rate scheduler\n",
        "    initial_lr = 5e-4\n",
        "    weight_decay = 1e-4\n",
        "    num_warmup_steps = dataset_size//(batch_size*5) #1 epoch\n",
        "    total_training_steps = epochs*(dataset_size//batch_size)\n",
        "    lr_min = 1e-4\n",
        "    lr_max = 1e-3\n",
        "\n",
        "\n",
        "    #tarflow\n",
        "    n_flow_steps = 8\n",
        "    permutation = True\n",
        "\n",
        "\n",
        "    #noising\n",
        "    noise_std = 0.1\n",
        "\n",
        "    #evaluation\n",
        "    evaluate = False\n",
        "    n_classes = 10\n",
        "\n",
        "    #guidance\n",
        "    guidance_on = True\n",
        "\n",
        "    #debug\n",
        "    debug = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5VeRpZlDQXZ",
        "outputId": "86f2962e-2c6c-458b-b984-ce771ce25e86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install numpy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HCDbnYZDF-OH"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(self, residual):\n",
        "        residual_mean = residual.mean(dim = -1, keepdim = True)\n",
        "        residual_std = (residual.var(dim = -1, keepdim = True, unbiased = False) + self.cfg.layer_norm_eps).sqrt()\n",
        "\n",
        "        residual = (residual - residual_mean) / residual_std\n",
        "        return residual * self.w + self.b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "x0xn_EcKG1mQ",
        "outputId": "a1e519b4-2649-4f3e-ed8d-9b08530499e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[12.6897, 10.2529, 10.1007,  8.4322, 12.4704, 10.4966],\n",
            "          [10.1129, 10.4757,  9.5170, 10.4776,  9.7355, 10.7460],\n",
            "          [ 9.8234,  8.9417, 11.7408,  9.7095,  9.0660,  9.8944],\n",
            "          [10.4973,  9.3982, 11.3753, 10.1840,  8.4599, 10.0840],\n",
            "          [11.6703, 10.1905,  8.4901, 11.2186, 10.2130,  9.5833],\n",
            "          [11.8352, 10.6641, 11.1505,  8.1411,  7.6911,  9.2362]]]])\n"
          ]
        }
      ],
      "source": [
        "#TESTER\n",
        "\n",
        "gaussian_sample = torch.normal(mean = 10, std = 1, size = (1, 1, 6, 6))\n",
        "print(gaussian_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzHmUGVKDRzj"
      },
      "outputs": [],
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: Image: float[Tensor, (bsize, channels, height, width)]\n",
        "    Output: Embedding: float[Tensor, (bsize, flattened_patch, d_model)]\n",
        "\n",
        "    Transforms an image into a learnable embedding (d_model dimensions) for each patch\n",
        "\n",
        "    Section 2.4: Reshape image to patches\n",
        "    B x C x H x W -> B x (HW/P_size^2) x (P_size^2 x C)\n",
        "\n",
        "    Paper doesn't give an invertible way to linear project the patches to the d_model dimension, so in this implementation we use an invertible linear projection\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def add_noise(self, images, cfg):\n",
        "        \"\"\"\n",
        "        Adds noise to the images for training\n",
        "        images: (bsize, channels, height, width)\n",
        "        cfg.noise_std: standard dev of the noise\n",
        "        \"\"\"\n",
        "        #adds noise N(0, std.dev) to images\n",
        "        return images + (torch.randn_like(images) * cfg.noise_std)\n",
        "\n",
        "    def forward(self, img):\n",
        "        img = self.add_noise(img, self.cfg)\n",
        "        img = torch.reshape(img, (img.size(0), self.cfg.num_patches, self.cfg.d_patch)) #B, C, H, W -> B, (HW/P^2), P^2 x C\n",
        "        return img\n",
        "\n",
        "    def reverse(self, z):\n",
        "        z = torch.reshape(z, (z.size(0), self.cfg.n_channels, self.cfg.img_size, self.cfg.img_size))\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ujuIf6S-HyJf",
        "outputId": "f7a740de-d2d9-4bf1-a86c-58c76f7f535f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[12.6897, 10.2529, 10.1007,  8.4322, 12.4704, 10.4966],\n",
            "          [10.1129, 10.4757,  9.5170, 10.4776,  9.7355, 10.7460],\n",
            "          [ 9.8234,  8.9417, 11.7408,  9.7095,  9.0660,  9.8944],\n",
            "          [10.4973,  9.3982, 11.3753, 10.1840,  8.4599, 10.0840],\n",
            "          [11.6703, 10.1905,  8.4901, 11.2186, 10.2130,  9.5833],\n",
            "          [11.8352, 10.6641, 11.1505,  8.1411,  7.6911,  9.2362]]]])\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "shape '[1, 49, 16]' is invalid for input of size 36",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ab088824dc35>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPAEM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPatchEmbed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaussian_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2 1 6 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mPAEM_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPAEM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaussian_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAEM_sample\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#2 4 9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-c062ff1f1e37>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_patches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#B, C, H, W -> B, (HW/P^2), P^2 x C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 49, 16]' is invalid for input of size 36"
          ]
        }
      ],
      "source": [
        "PAEM = PatchEmbed(Config())\n",
        "print(gaussian_sample) #2 1 6 6\n",
        "PAEM_sample = PAEM(gaussian_sample)\n",
        "print(PAEM_sample) #2 4 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KPU7tcEu6tWs",
        "outputId": "e95f73a1-5a55-4416-9934-4e52c4ac565a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "collapsed": true,
        "id": "rlFZlpod6rJG",
        "outputId": "6bd2066a-f094-4a3e-d59a-f28e05537127"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#This block shows that the noising step is working.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (_, _) = mnist.load_data()\n",
        "Patch_Embedder = PatchEmbed(cfg)\n",
        "# Create a 3x3 grid for 9 images\n",
        "fig, axes = plt.subplots(1, 3, figsize=(8, 8))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = Patch_Embedder.add_noise(torch.Tensor(x_train[i]), cfg)\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.set_title(f\"Label: {y_train[i]}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(6, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = x_train[i]\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.set_title(f\"Label: {y_train[i]}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "#print(\"NOISY 1\", Patch_Embedder.add_noise(torch.Tensor(x_train[0]), cfg))\n",
        "#print(\"UNNOISY 1\", x_train[0])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GyF5xpFqDWBo"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: Embedding: (bsize, flattened_patch, d_model)\n",
        "    Output: Pos + Class Encoded Embedding\n",
        "    Creates a positional encoding and class token for each patch\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.d_model = cfg.d_model\n",
        "        self.max_seq_length = cfg.max_seq_length\n",
        "        #self.cls_token = nn.Embedding(torch.randn(1, 1, cfg.d_patch)) #classification token, \"summary vector\"\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, self.max_seq_length, cfg.d_patch))\n",
        "        self.use_cls_token = cfg.guidance_on\n",
        "\n",
        "    def forward(self, embeddings, class_idx = None): #embeddings is Float[Tensor, \"bsize patch dmodel\"]\n",
        "        embeddings = embeddings + self.pos_embed[:, :embeddings.size(1), :]\n",
        "        #if self.use_cls_token and class_idx is not None:\n",
        "        #    class_tkn = self.class_tkn(class_idx)\n",
        "        #    class_tkn = class_tkn.unsqueeze(1).expand(-1, embeddings.size(1), -1)\n",
        "        #    embeddings = embeddings + class_tkn\n",
        "\n",
        "        return embeddings\n",
        "\n",
        "    def reverse(self, embeddings): #embeddings is Float[Tensor, \"bsize patch + 1 dmodel\"]\n",
        "        embeddings = embeddings - self.pos_embed[:, :embeddings.size(1), :]\n",
        "        #if self.use_cls_token:\n",
        "        #    embeddings = embeddings - self.current_class_tkn\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a40jbe-eJgLQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7e1ab607-a918-424f-f70e-73a7e1f5bc25"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PAEM_sample' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f59e9c717044>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#BEFORE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPAEM_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#AFTER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PAEM_sample' is not defined"
          ]
        }
      ],
      "source": [
        "#BEFORE\n",
        "print(PAEM_sample)\n",
        "print()\n",
        "\n",
        "#AFTER\n",
        "PE = PositionalEncoding(Config())\n",
        "PE_sample = PE(PAEM_sample)\n",
        "print(PE_sample) #added a little positional encoding to each (which is a learned weight parameter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrOGlddeDYqI"
      },
      "outputs": [],
      "source": [
        "class AttentionHead(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: Embeddings: (bsize patch dmodel)\n",
        "    Output: Attention output: (bsize patch dmodel)\n",
        "    Performs one attention head\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.query = nn.Linear(cfg.d_model, cfg.d_head)\n",
        "        self.key = nn.Linear(cfg.d_model, cfg.d_head)\n",
        "        self.value = nn.Linear(cfg.d_model, cfg.d_head)\n",
        "        self.output = nn.Linear(cfg.d_head, cfg.d_model)\n",
        "        self.cfg = cfg\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-float('inf')))\n",
        "        self.temp  = 1.0 #guidance in 2.6\n",
        "\n",
        "    def forward(self, embeddings, temp = None):  #bsize patch dmodel (embeddings)\n",
        "        \"\"\"\n",
        "        Takes in embeddings: (bsize patch dmodel)\n",
        "        \"\"\"\n",
        "\n",
        "        temp = temp if temp is not None else self.temp\n",
        "\n",
        "        # Calculate query, key and value vectors\n",
        "        Q = self.query(embeddings)  #bsize patch dmodel -> bsize patch dhead\n",
        "        K = self.key(embeddings) #bsize patch dmodel -> bsize patch dhead\n",
        "        V = self.value(embeddings) #bsize patch dmodel -> bsize patch dhead\n",
        "\n",
        "        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "        attn_scores = Q @ K.transpose(-1, -2) # -> bsize patch_q patch_k\n",
        "        attn_scores_scaled = attn_scores / self.cfg.d_head**0.5\n",
        "\n",
        "        if self.cfg.mask:\n",
        "            attn_scores_masked = self.apply_causal_mask(attn_scores_scaled) #scaled\n",
        "            attn_pattern = attn_scores_masked.softmax(-1) #softmaxed #bsize patch_q patch_k\n",
        "        else:\n",
        "            attn_pattern = attn_scores.softmax(-1)\n",
        "\n",
        "        attn_out = attn_pattern @ V #bsize patch_q dhead\n",
        "\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        \"\"\"\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        \"\"\"\n",
        "        # Define a mask that is True for all positions we want to set probabilities to zero for\n",
        "        all_ones = torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device)\n",
        "        mask = torch.triu(all_ones, diagonal=1).bool()\n",
        "        # Apply the mask to attention scores, then return the masked scores\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE) #IGNORE is -inf\n",
        "        return attn_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMLWQBnLDc6z"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: Embeddings: (bsize patch dmodel)\n",
        "    Output: Attention output: (bsize patch dmodel)\n",
        "    Performs multi-head attention\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.d_model = cfg.d_model\n",
        "        self.n_heads = cfg.n_heads\n",
        "        self.d_head = cfg.d_head\n",
        "\n",
        "        self.W_o = nn.Linear(self.n_heads * self.d_head, self.d_model)\n",
        "\n",
        "        #pass each through one attn head to get attn scores\n",
        "        self.heads = nn.ModuleList([AttentionHead(cfg) for _ in range(self.n_heads)])\n",
        "\n",
        "    def forward(self, embeddings): #B, patches, d_model\n",
        "        out = torch.cat([head(embeddings) for head in self.heads], dim = -1)\n",
        "        out = self.W_o(out) #B, patches, d_model\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "YbHRi56aPw_h"
      },
      "outputs": [],
      "source": [
        "#TESTING IF MHA WORKS\n",
        "print(\"MULTIHEAD ATTENTION VALUES\")\n",
        "MHA = MultiHeadAttention(Config())\n",
        "attention_values = MHA(Proj_PE_sample)\n",
        "print(attention_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeIusGd6De5L"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Input: Embeddings: (bsize patch dmodel)\n",
        "    Output: Encoded Embeddings: (bsize patch dmodel)\n",
        "    Performs one transformer encoder layer\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.d_model = cfg.d_model\n",
        "        self.n_heads = cfg.n_heads\n",
        "        self.dropout = nn.Dropout(cfg.dropout)\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.mha = MultiHeadAttention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(cfg.d_model, cfg.d_model * cfg.r_mlp),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(cfg.d_model*cfg.r_mlp, cfg.d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        out = embeddings + self.mha(self.ln1(embeddings))\n",
        "        #out = self.dropout(out)\n",
        "        out = out + self.mlp(self.ln2(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZsRbpfY3P8cz"
      },
      "outputs": [],
      "source": [
        "#TESTING IF TRANSFORMERENCODER WORKS\n",
        "TE = TransformerEncoder(Config())\n",
        "print(\"ENCODED VALUES\")\n",
        "encoded_values = TE(Proj_PE_sample)\n",
        "print(encoded_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3giF7nJuDhFP"
      },
      "outputs": [],
      "source": [
        "class Permutation(nn.Module): #post patch embedding\n",
        "    \"\"\"\n",
        "    Creates the permutation function (reversal) following p.3 in paper\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config): #batch_size, num_patches, d_model\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def forward(self, x): #batch_size, num_patches, d_model\n",
        "        permuted = torch.flip(x, dims = [1])\n",
        "        return permuted\n",
        "\n",
        "    def reverse(self, x): #batch_size, num_patches, d_model\n",
        "        permuted = torch.flip(x, dims = [1])\n",
        "        return permuted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ywccI99oQGpn"
      },
      "outputs": [],
      "source": [
        "#TESTING IF PERMUTATION WORKS\n",
        "print(\"BEFORE:\")\n",
        "print(Proj_PE_sample)\n",
        "\n",
        "print(\"PERMUTED:\")\n",
        "P = Permutation(Config())\n",
        "permuted_sample = P(Proj_PE_sample)\n",
        "print(permuted_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tm820PxDjE6"
      },
      "outputs": [],
      "source": [
        "class AffineTransform(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the affine transform (eq. 3) in the paper\n",
        "\n",
        "    Input: x: (bsize, num_patches, d_model)\n",
        "    mu: (learned linear, gelu, linear)\n",
        "    alpha: (learned linear, gelu, linear )\n",
        "    output: newx: (bsize, num_patches, d_model)\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def forward(self, x, mu, alpha): #batch_size, num_patches, d_model\n",
        "        new_x = torch.zeros_like(x)\n",
        "\n",
        "        new_x[:, 0, :] = x[:, 0, :] #batch_size, first_patch, d_model\n",
        "    #TODO: check if clamp is needed\n",
        "        #alpha = torch.clamp(alpha, min=-10.0, max=10.0)\n",
        "        new_x[:, 1:, :] = (x[:, 1:, :] - mu[:, 1:, :]) * torch.exp(-alpha[:, 1:, :]) #batch_size, num_patches - 1, d_model\n",
        "        return new_x\n",
        "\n",
        "    def inverse(self, z, mu, alpha):\n",
        "    #TODO: check if clamp is needed\n",
        "        #alpha = torch.clamp(alpha, min=-10.0, max=10.0) #alpha is batch size, dpatch\n",
        "\n",
        "        return z * torch.exp(alpha) + mu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skCT7FJrQyYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvEudzIoDls5"
      },
      "outputs": [],
      "source": [
        "class TransformerFlowBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Runs a transformer encoder that learns one flow step, then applies the affine transform\n",
        "    Follows flow step in eq. 3 in paper\n",
        "\n",
        "    Input: Images: (bsize, numpatches, d patch)\n",
        "    Output: Transformed Embeddings: (bsize, num_patches, d_patch)\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg, block_id):\n",
        "        super().__init__()\n",
        "        self.block_id = block_id\n",
        "        cfg.mask = True\n",
        "\n",
        "\n",
        "        assert cfg.img_size % cfg.patch_size == 0  #assume working with square patches\n",
        "        assert cfg.d_model % cfg.n_heads == 0\n",
        "\n",
        "        self.transformer_encoder = nn.ModuleList([TransformerEncoder(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.proj_to_model = nn.Linear(cfg.d_patch, cfg.d_model)\n",
        "        self.proj_to_patch = nn.Linear(cfg.d_model, 2 * cfg.d_patch)\n",
        "        #TODO: paper doesn't have these initializations, but without them my model scales to inf\n",
        "        self.proj_to_model.weight.data.fill_(0.0)\n",
        "        self.proj_to_patch.weight.data.fill_(0.0)\n",
        "        self.permutation = Permutation(cfg)\n",
        "        self.affine_transform = AffineTransform(cfg)\n",
        "        self.pos_embed_add = torch.nn.Parameter(torch.randn(cfg.max_seq_length, cfg.d_model) * 1e-2)\n",
        "        nn.init.zeros_(self.pos_embed_add)\n",
        "\n",
        "\n",
        "    def forward(self, z_t, temp = None, uncond_out = None): #batch_size, num_patches, d_model\n",
        "            #print(images)\n",
        "            #print(f\"Flow block {self.block_id} FORWARD\")\n",
        "            z_t = self.permutation(z_t)\n",
        "            z_orig = z_t\n",
        "            z_t_proj = self.proj_to_model(z_t) + self.permutation(self.pos_embed_add[:z_t.shape[1]]) #batch size, num patches, dmodel\n",
        "\n",
        "            encoded = z_t_proj\n",
        "            for layer in self.transformer_encoder:\n",
        "                encoded = layer(encoded)\n",
        "\n",
        "            z_t = self.proj_to_patch(encoded) #batch size, num patches, 2 * dpatch\n",
        "            #z_t = torch.cat([torch.zeros_like(z_t[:, :1]), z_t[:, :-1]], dim = 1) #0, ... remove this manual shift\n",
        "\n",
        "            mu, alpha = z_t.chunk(2, dim = -1) #batch size, num patches, dpatch each\n",
        "            #print(\"alpha size forward\", alpha.size())\n",
        "\n",
        "            z_t1 = self.affine_transform(z_orig, mu, alpha) #second residual connection over the latents\n",
        "            logdet = -alpha.mean(dim = [1, 2])\n",
        "            return self.permutation(z_t1), logdet\n",
        "\n",
        "    def reverse_step(self, z, i):\n",
        "            \"\"\"\n",
        "            gets mu, alpha for going from z_t to z_{t-1}\n",
        "            \"\"\"\n",
        "            z_in = z[:, i:i+1] #gets the ith patch, keeping the sequence dimension\n",
        "            #print(\"z in dim\", z_in.size())\n",
        "\n",
        "            z = self.proj_to_model(z_in) + self.pos_embed_add[i:i+1].unsqueeze(0)\n",
        "            #print (\"z after proj model\", z.size())\n",
        "            for layer in self.transformer_encoder:\n",
        "                z = layer(z)\n",
        "            z = self.proj_to_patch(z) #project to batch size, num_patches, 2 * dpatch\n",
        "            mu, alpha = z.chunk(2, dim = -1) #batch size, dpatch\n",
        "            #print(\"alpha size\", alpha.size())\n",
        "\n",
        "            return mu, alpha\n",
        "\n",
        "    def reverse(self, z):\n",
        "        z = self.permutation(z)\n",
        "        pos_embed = self.permutation(self.pos_embed_add)\n",
        "        num_patches = z.size(1)\n",
        "\n",
        "        for i in range(num_patches - 1):\n",
        "          zmu, zalpha = self.reverse_step(z, i)\n",
        "          z[:, i+1:i+2] = self.affine_transform.inverse(z[:, i+1:i+2], zmu, zalpha) #batchsize, numpatches, dpatch\n",
        "\n",
        "        return self.permutation(z)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ_-wu1FDxiV"
      },
      "outputs": [],
      "source": [
        "class Tarflow(nn.Module):\n",
        "    \"\"\"\n",
        "    Puts together all flow steps + transformer architecture\n",
        "    Following figure 2 in paper\n",
        "\n",
        "    Input: Images: (bsize, channels, height, width)\n",
        "    Output: latent space image: (bsize, num_patches, channels * height * width)\n",
        "    \"\"\"\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.patch_embedding = PatchEmbed(cfg)\n",
        "        self.positional_encoding = PositionalEncoding(cfg)\n",
        "        self.transformer_flow_blocks = nn.ModuleList([TransformerFlowBlock(cfg, block_id = i) for i in range(cfg.n_flow_steps)])\n",
        "\n",
        "    def encode(self, images):\n",
        "        #print(\"ENCODING\")\n",
        "        outputs = []\n",
        "        logdets = torch.zeros((), device = images.device)\n",
        "\n",
        "        x = self.patch_embedding(images)\n",
        "\n",
        "        for i in range(len(self.transformer_flow_blocks)):\n",
        "            block = self.transformer_flow_blocks[i]\n",
        "            x, logdet = block(x)\n",
        "            logdets = logdets + logdet\n",
        "            outputs.append(x)\n",
        "\n",
        "        return x, outputs, logdets #outputs is step-by-step transformation\n",
        "\n",
        "    def loss_function(self, x, logdets):\n",
        "        \"\"\"\n",
        "        Following loss function (eq. 6) in the paper,\n",
        "        L = 0.5 * ||x||^2 + sum of alphas\n",
        "        \"\"\"\n",
        "        #print(\"REACHED\")\n",
        "        print()\n",
        "        gaussian_loss = 0.5 * x.pow(2).mean()\n",
        "        logdet_loss = logdets.mean()\n",
        "        #print(\"LOGDETS MEAN\", logdet_loss)\n",
        "        #print()\n",
        "        #print(\"GAUSSIAN LOSS\", gaussian_loss)\n",
        "        #print()\n",
        "        prior_loss = gaussian_loss - logdets.mean()  # batch size\n",
        "        #print(\"prior loss\", prior_loss)\n",
        "        if self.cfg.debug:  # optional: only log if in debug mode\n",
        "          wandb.log({\n",
        "              \"gaussian_loss\": gaussian_loss.item(),\n",
        "              \"logdet_loss\": logdet_loss.item(),\n",
        "              \"total_loss\": prior_loss.item()\n",
        "          })\n",
        "        return prior_loss\n",
        "\n",
        "\n",
        "\n",
        "    def decode(self, z, temp=1.0): #z is B, N, D\n",
        "        patches = [self.patch_embedding.reverse(z)] #goes to B, 1, 28, 28\n",
        "        for block in reversed(self.transformer_flow_blocks):\n",
        "          z = block.reverse(z) #z is still patchified B, N ,D\n",
        "          patches.append(self.patch_embedding.reverse(z))\n",
        "        return z #still patchified\n",
        "\n",
        "    def denoise(self, y, sigma = 0.1):\n",
        "        \"\"\"\n",
        "        Adds score-based denoising from section 2.5\n",
        "        \"\"\"\n",
        "        sigma = self.cfg.noise_std\n",
        "\n",
        "        #encode to get log p_model with negative log_likelihood\n",
        "        y = y.clone().detach().requires_grad_(True) #detach kills connection to computation graph\n",
        "        z, _, logdets = self.encode(self.patch_embedding.reverse(y))\n",
        "        loss = 0.5 * z.pow(2).mean() - logdets.mean()\n",
        "\n",
        "        grad = torch.autograd.grad(loss, y, create_graph = False)[0] #gets first input grad\n",
        "\n",
        "        x = y + (sigma **2) * grad\n",
        "        return x.detach() #stops gradient tracking\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgTCfoyPEHlO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def generate_latents(self, model, num_samples, device = None):\n",
        "        \"\"\"\n",
        "        Take samples from the latent space\n",
        "        Generate images\n",
        "        \"\"\"\n",
        "\n",
        "        if device is None:\n",
        "            device = next(model.parameters()).device\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        cfg = model.cfg\n",
        "        #num_patches = cfg.num_patches + 1\n",
        "\n",
        "        z = 256 * torch.randn(num_samples, cfg.num_patches, cfg.d_patch).to(device)\n",
        "        noisy = model.patch_embedding.reverse(z[:16])\n",
        "        wandb.log({\"random noise\": [wandb.Image(noise) for noise in noisy]})\n",
        "        # Visual sanity check\n",
        "\n",
        "        with torch.no_grad():\n",
        "            decoded_images = model.decode(z)\n",
        "\n",
        "        grid = model.patch_embedding.reverse(decoded_images[:16])\n",
        "        wandb.log({\"before denoising\": [wandb.Image(grid_image) for grid_image in grid]})\n",
        "\n",
        "\n",
        "        denoised = model.denoise(decoded_images)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            images = model.patch_embedding.reverse(denoised)\n",
        "\n",
        "\n",
        "        return images\n",
        "\n",
        "    def visualize_generated_images(self, images, nrow = 4, title = \"Generated Images\"):\n",
        "        \"\"\"\n",
        "        Visualize generated images in a grid\n",
        "        \"\"\"\n",
        "\n",
        "        if images.device.type != 'cpu':\n",
        "            images = images.cpu()\n",
        "\n",
        "        #make a grid\n",
        "        from torchvision.utils import make_grid\n",
        "        grid = make_grid(images, nrow = nrow, normalize = True)\n",
        "        grid = grid.numpy()\n",
        "\n",
        "        #convert to numpy\n",
        "        grid_np = np.transpose(grid, (1, 2, 0))\n",
        "\n",
        "        #Plot\n",
        "        plt.figure(figsize = (10, 10))\n",
        "        if grid_np.shape[2] == 1: # if grayscale\n",
        "            plt.imshow(grid_np[:, :, 0], cmap = \"gray\")\n",
        "        else:\n",
        "            plt.imshow(grid_np)\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "        plt.savefig(f'generated_{title.lower().replace(\" \", \"_\")}.png')\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULaxjUiAD1Dm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch.optim import AdamW\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "def train_model(model, config): #mnist trainer\n",
        "  cfg  = config\n",
        "  wandb.init(project=\"tarflow\", config = vars(cfg), name=\"MNIST-RUN\")\n",
        "\n",
        "  config = wandb.config\n",
        "\n",
        "  img_size = (cfg.img_size, cfg.img_size)\n",
        "  batch_size = cfg.batch_size\n",
        "  epochs = cfg.epochs\n",
        "\n",
        "  transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,), (0.5,))\n",
        "  ])\n",
        "\n",
        "  train_set = MNIST(\n",
        "    root=\"./../datasets\", train=True, download=True, transform=transform\n",
        "  )\n",
        "  test_set = MNIST(\n",
        "    root=\"./../datasets\", train=False, download=True, transform=transform\n",
        "  )\n",
        "\n",
        "  train_loader = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
        "  test_loader = DataLoader(test_set, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
        "\n",
        "  my_model =  model.to(device)\n",
        "  #print(\"My_Model\", my_model)\n",
        "\n",
        "  #TODO: change lr\n",
        "  optimizer = AdamW(my_model.parameters(), lr=cfg.initial_lr, weight_decay = cfg.weight_decay, betas = (0.9, 0.95))\n",
        "\n",
        "\n",
        "  scheduler = cosine_scheduler_with_warmup(cfg, optimizer)\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "\n",
        "    training_loss = 0.0\n",
        "    for i, data in enumerate(tqdm(train_loader, desc=\"Training\", leave = False), 0):\n",
        "      inputs, _ = data\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      x, outputs, log_dets = my_model.encode(inputs)\n",
        "      loss = my_model.loss_function(x, log_dets)\n",
        "      loss.backward()\n",
        "      wandb.log({\n",
        "        \"loss\": loss.item(),\n",
        "        \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "        \"step\": epoch * len(train_loader) + i\n",
        "      })\n",
        "      optimizer.step()\n",
        "\n",
        "      if cfg.has_scheduler: #if we want a lr scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "      training_loss += loss.item()\n",
        "      if i % 1 == 0:  # print loss very 20 batches\n",
        "        print(f'  Batch {i}/{len(train_loader)}, Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs} loss: {training_loss  / len(train_loader) :.3f}')\n",
        "\n",
        "  generator = Generator(cfg)\n",
        "  generated_images = generator.generate_latents(my_model, num_samples = cfg.batch_size, device = device)\n",
        "  wandb.log({\"generated_images\": [wandb.Image(img) for img in generated_images]})\n",
        "\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  if cfg.evaluate:\n",
        "    with torch.no_grad():\n",
        "      for data in tqdm(test_loader, desc=\"Testing\", leave = False):\n",
        "        images, labels = data\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "      outputs = my_model(images)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "    print(f'\\nModel Accuracy: {100 * correct // total} %')\n",
        "\n",
        "  wandb.finish()\n",
        "\n",
        "def cosine_scheduler_with_warmup(cfg, optimizer):\n",
        "  \"\"\"\n",
        "  config consists of:\n",
        "  num_warmup_steps, num_training_steps, lr_min, lr_max, weight_decay,\n",
        "\n",
        "  creates a lambda scheduler function that returns the learning rate for a given step\n",
        "\n",
        "  warmup goes from lr_min to lr_max in num_warmup_steps\n",
        "\n",
        "  cosine decay goes from lr_max back to lr_min in remaining # steps\n",
        "  \"\"\"\n",
        "  def lr_lambda(current_step):\n",
        "    #warmup phase\n",
        "    if current_step < cfg.num_warmup_steps:\n",
        "      print(\"lr\", cfg.lr_min + (cfg.lr_max - cfg.lr_min) * current_step / cfg.num_warmup_steps)\n",
        "\n",
        "      return cfg.lr_min + (cfg.lr_max - cfg.lr_min) * current_step / cfg.num_warmup_steps\n",
        "\n",
        "    #cosine decay phase\n",
        "    progress = (current_step - cfg.num_warmup_steps) / (cfg.total_training_steps - cfg.num_warmup_steps) #which step we're on of training\n",
        "\n",
        "    cosine_decay = 0.5 * (1 + torch.cos(torch.tensor(torch.pi) * progress))\n",
        "\n",
        "    lr = cfg.lr_min + (cfg.lr_max - cfg.lr_min) * cosine_decay\n",
        "    return lr\n",
        "\n",
        "  return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ml9oKuHHnpy"
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_corner_cluster(n_samples = 1000, center = (5.0, 5.0), std = 0.1):\n",
        "  return torch.randn(n_samples, 2) * std + torch.tensor(center)\n",
        "\n",
        "\n",
        "cfg.num_patches = 1\n",
        "cfg.d_patch = 2\n",
        "cfg.d_model = 32\n",
        "cfg.epochs = 20\n",
        "\n",
        "model = Tarflow(cfg)\n",
        "\n",
        "x = sample_corner_cluster(1000) #b, 2\n",
        "x = x.unsqueeze(1) #b, 1, 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch.optim import AdamW\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "def train_model(model, config): #mnist trainer\n",
        "  cfg  = config\n",
        "  wandb.init(project=\"tarflow\", config = vars(cfg), name=\"MINI-GAUSSIAN-RUN\")\n",
        "\n",
        "  config = wandb.config\n",
        "\n",
        "  img_size = (cfg.img_size, cfg.img_size)\n",
        "  batch_size = cfg.batch_size\n",
        "  epochs = 1000\n",
        "\n",
        "  transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.5,), (0.5,))\n",
        "  ])\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
        "\n",
        "  my_model =  model.to(device)\n",
        "\n",
        "  optimizer = AdamW(my_model.parameters(), lr=cfg.initial_lr, weight_decay = cfg.weight_decay, betas = (0.9, 0.95))\n",
        "\n",
        "  corner_cluster = sample_corner_cluster(1000) #b, 2\n",
        "\n",
        "  scheduler = cosine_scheduler_with_warmup(cfg, optimizer)\n",
        "\n",
        "\n",
        "  for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "\n",
        "    training_loss = 0.0\n",
        "    inputs = corner_cluster\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x, outputs, log_dets = my_model.encode(inputs)\n",
        "    loss = my_model.loss_function(x, log_dets)\n",
        "    loss.backward()\n",
        "    wandb.log({\n",
        "      \"loss\": loss.item(),\n",
        "      \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "      \"step\": epoch * 1 + i\n",
        "    })\n",
        "    optimizer.step()\n",
        "\n",
        "    if cfg.has_scheduler: #if we want a lr scheduler\n",
        "      scheduler.step()\n",
        "\n",
        "    training_loss += loss.item()\n",
        "    if i % 1 == 0:  # print loss very 20 batches\n",
        "      print(f'  Batch {i}/{1}, Loss: {loss.item():.4f}, LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs} loss: {training_loss  / 1 :.3f}')\n",
        "\n",
        "  generator = Generator(cfg)\n",
        "  model.patch_embedding.reverse = lambda z: z\n",
        "  generated_images = generator.generate_latents(my_model, num_samples = 1, device = device)\n",
        "  wandb.log({\"generated_images\": [wandb.Image(img) for img in generated_images]})\n",
        "\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  wandb.finish()\n",
        "\n",
        "def cosine_scheduler_with_warmup(cfg, optimizer):\n",
        "  \"\"\"\n",
        "  config consists of:\n",
        "  num_warmup_steps, num_training_steps, lr_min, lr_max, weight_decay,\n",
        "\n",
        "  creates a lambda scheduler function that returns the learning rate for a given step\n",
        "\n",
        "  warmup goes from lr_min to lr_max in num_warmup_steps\n",
        "\n",
        "  cosine decay goes from lr_max back to lr_min in remaining # steps\n",
        "  \"\"\"\n",
        "  def lr_lambda(current_step):\n",
        "    #warmup phase\n",
        "    if current_step < cfg.num_warmup_steps:\n",
        "      print(\"lr\", cfg.lr_min + (cfg.lr_max - cfg.lr_min) * current_step / cfg.num_warmup_steps)\n",
        "\n",
        "      return cfg.lr_min + (cfg.lr_max - cfg.lr_min) * current_step / cfg.num_warmup_steps\n",
        "\n",
        "    #cosine decay phase\n",
        "    progress = (current_step - cfg.num_warmup_steps) / (cfg.total_training_steps - cfg.num_warmup_steps) #which step we're on of training\n",
        "\n",
        "    cosine_decay = 0.5 * (1 + torch.cos(torch.tensor(torch.pi) * progress))\n",
        "\n",
        "    lr = cfg.lr_min + (cfg.lr_max - cfg.lr_min) * cosine_decay\n",
        "    return lr\n",
        "\n",
        "  return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "\n",
        "train_model(Tarflow(cfg), cfg)"
      ],
      "metadata": {
        "id": "zC5X0hBGF3x_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "5cf7b02f-91c2-4cde-a942-e3aee9f34453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250404_154417-z5dusu47</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/z5dusu47' target=\"_blank\">MINI-GAUSSIAN-RUN</a></strong> to <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow' target=\"_blank\">https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/z5dusu47' target=\"_blank\">https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/z5dusu47</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda (NVIDIA A100-SXM4-40GB)\n",
            "lr 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8c0e534cc876>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTarflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-8c0e534cc876>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, config)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-47456848be81>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_flow_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_flow_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mlogdets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdets\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-93b34586a120>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z_t, temp, uncond_out)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz_t_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mz_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_to_patch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#batch size, num patches, 2 * dpatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-bd472f9c2697>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#out = self.dropout(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f64a6390ec8a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#B, patches, d_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#B, patches, d_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f64a6390ec8a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#B, patches, d_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_o\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#B, patches, d_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-caab36eda6dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings, temp)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Calculate query, key and value vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#bsize patch dmodel -> bsize patch dhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#bsize patch dmodel -> bsize patch dhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#bsize patch dmodel -> bsize patch dhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XGyag0YmEOyA",
        "outputId": "e88cc629-775a-4c75-91d9-348fe8c50ad9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>gaussian_loss</td><td>nan</td></tr><tr><td>logdet_loss</td><td>nan</td></tr><tr><td>loss</td><td>nan</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>step</td><td>42</td></tr><tr><td>total_loss</td><td>nan</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">MNIST-RUN</strong> at: <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/j8mcmj25' target=\"_blank\">https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/j8mcmj25</a><br> View project at: <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow' target=\"_blank\">https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250404_183812-j8mcmj25/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250404_184112-2j70swp3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/2j70swp3' target=\"_blank\">MNIST-RUN</a></strong> to <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow' target=\"_blank\">https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/2j70swp3' target=\"_blank\">https://wandb.ai/kaynelu921-massachusetts-institute-of-technology/tarflow/runs/2j70swp3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda (NVIDIA A100-SXM4-40GB)\n",
            "lr 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "Training:   0%|          | 1/469 [00:00<01:04,  7.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00010967741935483871\n",
            "  Batch 0/469, Loss: 0.4561, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 2/469 [00:00<00:59,  7.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00011935483870967743\n",
            "  Batch 1/469, Loss: 0.4559, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|          | 3/469 [00:00<00:58,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00012903225806451613\n",
            "  Batch 2/469, Loss: 0.4587, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|          | 4/469 [00:00<00:57,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00013870967741935484\n",
            "  Batch 3/469, Loss: 0.4566, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|          | 5/469 [00:00<00:56,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00014838709677419355\n",
            "  Batch 4/469, Loss: 0.4574, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|▏         | 6/469 [00:00<00:56,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00015806451612903228\n",
            "  Batch 5/469, Loss: 0.4580, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|▏         | 7/469 [00:00<00:56,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00016774193548387098\n",
            "  Batch 6/469, Loss: 0.4577, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 8/469 [00:00<00:55,  8.32it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0001774193548387097\n",
            "  Batch 7/469, Loss: 0.4576, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 9/469 [00:01<00:55,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0001870967741935484\n",
            "  Batch 8/469, Loss: 0.4582, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 10/469 [00:01<00:55,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0001967741935483871\n",
            "  Batch 9/469, Loss: 0.4573, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 11/469 [00:01<00:55,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0002064516129032258\n",
            "  Batch 10/469, Loss: 0.4593, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 12/469 [00:01<00:55,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0002161290322580645\n",
            "  Batch 11/469, Loss: 0.4575, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 13/469 [00:01<00:55,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00022580645161290321\n",
            "  Batch 12/469, Loss: 0.4586, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 14/469 [00:01<00:55,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00023548387096774192\n",
            "  Batch 13/469, Loss: 0.4575, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 15/469 [00:01<00:54,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0002451612903225806\n",
            "  Batch 14/469, Loss: 0.4564, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 16/469 [00:01<00:54,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00025483870967741933\n",
            "  Batch 15/469, Loss: 0.4570, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▎         | 17/469 [00:02<00:54,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00026451612903225804\n",
            "  Batch 16/469, Loss: 0.4564, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 18/469 [00:02<00:54,  8.31it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0002741935483870968\n",
            "  Batch 17/469, Loss: 0.4565, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 19/469 [00:02<00:55,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0002838709677419355\n",
            "  Batch 18/469, Loss: 0.4578, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 20/469 [00:02<00:55,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0002935483870967742\n",
            "  Batch 19/469, Loss: 0.4571, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 21/469 [00:02<00:54,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0003032258064516129\n",
            "  Batch 20/469, Loss: 0.4570, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▍         | 22/469 [00:02<00:55,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0003129032258064516\n",
            "  Batch 21/469, Loss: 0.4570, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▍         | 23/469 [00:02<00:55,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0003225806451612903\n",
            "  Batch 22/469, Loss: 0.4572, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▌         | 24/469 [00:02<00:54,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00033225806451612903\n",
            "  Batch 23/469, Loss: 0.4578, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▌         | 25/469 [00:03<00:54,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00034193548387096773\n",
            "  Batch 24/469, Loss: 0.4571, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 26/469 [00:03<00:54,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00035161290322580644\n",
            "  Batch 25/469, Loss: 0.4581, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 27/469 [00:03<00:53,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00036129032258064514\n",
            "  Batch 26/469, Loss: 0.4564, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 28/469 [00:03<00:53,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00037096774193548385\n",
            "  Batch 27/469, Loss: 0.4575, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 29/469 [00:03<00:53,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00038064516129032255\n",
            "  Batch 28/469, Loss: 0.4559, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▋         | 30/469 [00:03<00:53,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00039032258064516126\n",
            "  Batch 29/469, Loss: 0.4565, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 31/469 [00:03<00:53,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00039999999999999996\n",
            "  Batch 30/469, Loss: 0.4560, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 32/469 [00:03<00:53,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00040967741935483867\n",
            "  Batch 31/469, Loss: 0.4573, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 33/469 [00:04<00:52,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00041935483870967743\n",
            "  Batch 32/469, Loss: 0.4561, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 34/469 [00:04<00:52,  8.33it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0004290322580645161\n",
            "  Batch 33/469, Loss: 0.4573, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 35/469 [00:04<00:52,  8.29it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00043870967741935484\n",
            "  Batch 34/469, Loss: 0.4559, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 36/469 [00:04<00:52,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00044838709677419355\n",
            "  Batch 35/469, Loss: 0.4573, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 37/469 [00:04<00:52,  8.17it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0004580645161290322\n",
            "  Batch 36/469, Loss: 0.4571, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 38/469 [00:04<00:52,  8.18it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00046774193548387096\n",
            "  Batch 37/469, Loss: 0.4569, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 39/469 [00:04<00:52,  8.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00047741935483870966\n",
            "  Batch 38/469, Loss: 0.4568, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▊         | 40/469 [00:04<00:51,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.00048709677419354837\n",
            "  Batch 39/469, Loss: 0.4568, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▊         | 41/469 [00:04<00:51,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0004967741935483871\n",
            "  Batch 40/469, Loss: 0.4567, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▉         | 42/469 [00:05<00:51,  8.35it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005064516129032258\n",
            "  Batch 41/469, Loss: 0.4564, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▉         | 43/469 [00:05<00:50,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005161290322580645\n",
            "  Batch 42/469, Loss: 0.4567, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▉         | 44/469 [00:05<00:50,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005258064516129032\n",
            "  Batch 43/469, Loss: 0.4561, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|▉         | 45/469 [00:05<00:50,  8.36it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000535483870967742\n",
            "  Batch 44/469, Loss: 0.4553, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|▉         | 46/469 [00:05<00:50,  8.38it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005451612903225807\n",
            "  Batch 45/469, Loss: 0.4571, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|█         | 47/469 [00:05<00:50,  8.38it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005548387096774194\n",
            "  Batch 46/469, Loss: 0.4568, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|█         | 48/469 [00:05<00:50,  8.30it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005645161290322581\n",
            "  Batch 47/469, Loss: 0.4565, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|█         | 49/469 [00:05<00:51,  8.21it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005741935483870968\n",
            "  Batch 48/469, Loss: 0.4552, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█         | 50/469 [00:06<00:50,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005838709677419355\n",
            "  Batch 49/469, Loss: 0.4557, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█         | 51/469 [00:06<00:50,  8.28it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0005935483870967742\n",
            "  Batch 50/469, Loss: 0.4565, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█         | 52/469 [00:06<00:50,  8.27it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006032258064516129\n",
            "  Batch 51/469, Loss: 0.4542, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█▏        | 53/469 [00:06<00:50,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006129032258064517\n",
            "  Batch 52/469, Loss: 0.4559, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 54/469 [00:06<00:50,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006225806451612904\n",
            "  Batch 53/469, Loss: 0.4550, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 55/469 [00:06<00:50,  8.19it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000632258064516129\n",
            "  Batch 54/469, Loss: 0.4549, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 56/469 [00:06<00:50,  8.24it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006419354838709678\n",
            "  Batch 55/469, Loss: 0.4562, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 57/469 [00:06<00:49,  8.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006516129032258065\n",
            "  Batch 56/469, Loss: 0.4555, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 58/469 [00:07<00:49,  8.26it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006612903225806452\n",
            "  Batch 57/469, Loss: 0.4559, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 59/469 [00:07<00:49,  8.23it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006709677419354839\n",
            "  Batch 58/469, Loss: 0.4543, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 60/469 [00:07<00:49,  8.20it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006806451612903226\n",
            "  Batch 59/469, Loss: 0.4550, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 61/469 [00:07<00:50,  8.15it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0006903225806451613\n",
            "  Batch 60/469, Loss: 0.4552, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 62/469 [00:07<00:50,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007\n",
            "  Batch 61/469, Loss: 0.4548, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 63/469 [00:07<00:50,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007096774193548388\n",
            "  Batch 62/469, Loss: 0.4546, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▎        | 64/469 [00:07<00:50,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007193548387096774\n",
            "  Batch 63/469, Loss: 0.4528, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 65/469 [00:07<00:49,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007290322580645162\n",
            "  Batch 64/469, Loss: 0.4549, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 66/469 [00:08<00:49,  8.10it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007387096774193549\n",
            "  Batch 65/469, Loss: 0.4549, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 67/469 [00:08<00:49,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007483870967741936\n",
            "  Batch 66/469, Loss: 0.4551, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 68/469 [00:08<00:49,  8.16it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007580645161290322\n",
            "  Batch 67/469, Loss: 0.4533, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▍        | 69/469 [00:08<00:49,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000767741935483871\n",
            "  Batch 68/469, Loss: 0.4534, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▍        | 70/469 [00:08<00:49,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007774193548387097\n",
            "  Batch 69/469, Loss: 0.4543, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▌        | 71/469 [00:08<00:49,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007870967741935484\n",
            "  Batch 70/469, Loss: 0.4544, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▌        | 72/469 [00:08<00:49,  8.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0007967741935483872\n",
            "  Batch 71/469, Loss: 0.4531, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 73/469 [00:08<00:49,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008064516129032258\n",
            "  Batch 72/469, Loss: 0.4553, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 74/469 [00:09<00:48,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008161290322580645\n",
            "  Batch 73/469, Loss: 0.4539, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 75/469 [00:09<00:48,  8.07it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008258064516129033\n",
            "  Batch 74/469, Loss: 0.4547, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 76/469 [00:09<00:48,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000835483870967742\n",
            "  Batch 75/469, Loss: 0.4524, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▋        | 77/469 [00:09<00:48,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008451612903225807\n",
            "  Batch 76/469, Loss: 0.4538, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 78/469 [00:09<00:48,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008548387096774194\n",
            "  Batch 77/469, Loss: 0.4541, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 79/469 [00:09<00:48,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000864516129032258\n",
            "  Batch 78/469, Loss: 0.4536, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 80/469 [00:09<00:48,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008741935483870968\n",
            "  Batch 79/469, Loss: 0.4535, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 81/469 [00:09<00:48,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008838709677419354\n",
            "  Batch 80/469, Loss: 0.4527, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 82/469 [00:10<00:48,  7.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0008935483870967743\n",
            "  Batch 81/469, Loss: 0.4532, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 83/469 [00:10<00:48,  8.04it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000903225806451613\n",
            "  Batch 82/469, Loss: 0.4529, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 84/469 [00:10<00:47,  8.05it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0009129032258064516\n",
            "  Batch 83/469, Loss: 0.4523, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 85/469 [00:10<00:47,  8.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0009225806451612904\n",
            "  Batch 84/469, Loss: 0.4533, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 86/469 [00:10<00:48,  7.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000932258064516129\n",
            "  Batch 85/469, Loss: 0.4532, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▊        | 87/469 [00:10<00:47,  8.03it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0009419354838709677\n",
            "  Batch 86/469, Loss: 0.4517, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 88/469 [00:10<00:47,  8.09it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0009516129032258064\n",
            "  Batch 87/469, Loss: 0.4517, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 89/469 [00:10<00:46,  8.13it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0009612903225806453\n",
            "  Batch 88/469, Loss: 0.4523, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 90/469 [00:11<00:47,  8.02it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.000970967741935484\n",
            "  Batch 89/469, Loss: 0.4516, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 91/469 [00:11<00:46,  8.06it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0009806451612903225\n",
            "  Batch 90/469, Loss: 0.4529, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|█▉        | 92/469 [00:11<00:46,  8.11it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr 0.0009903225806451614\n",
            "  Batch 91/469, Loss: 0.4512, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|█▉        | 93/469 [00:11<00:46,  8.12it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 92/469, Loss: 0.4514, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|██        | 94/469 [00:11<00:51,  7.25it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 93/469, Loss: 0.4504, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|██        | 95/469 [00:11<00:55,  6.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 94/469, Loss: 0.4503, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|██        | 96/469 [00:11<00:57,  6.44it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 95/469, Loss: 0.4516, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██        | 97/469 [00:12<00:59,  6.22it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 96/469, Loss: 0.4522, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██        | 98/469 [00:12<01:01,  6.08it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 97/469, Loss: 0.4519, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██        | 99/469 [00:12<01:01,  5.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 98/469, Loss: 0.4527, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██▏       | 100/469 [00:12<01:02,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 99/469, Loss: 0.4519, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 101/469 [00:12<01:02,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 100/469, Loss: 0.4514, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 102/469 [00:12<01:02,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 101/469, Loss: 0.4494, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 103/469 [00:13<01:02,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 102/469, Loss: 0.4511, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 104/469 [00:13<01:02,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 103/469, Loss: 0.4494, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 105/469 [00:13<01:02,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 104/469, Loss: 0.4513, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 106/469 [00:13<01:02,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 105/469, Loss: 0.4496, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 107/469 [00:13<01:02,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 106/469, Loss: 0.4509, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 108/469 [00:13<01:02,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 107/469, Loss: 0.4512, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 109/469 [00:14<01:01,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 108/469, Loss: 0.4492, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 110/469 [00:14<01:02,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 109/469, Loss: 0.4481, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▎       | 111/469 [00:14<01:02,  5.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 110/469, Loss: 0.4491, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▍       | 112/469 [00:14<01:02,  5.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 111/469, Loss: 0.4498, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▍       | 113/469 [00:14<01:02,  5.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 112/469, Loss: 0.4501, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▍       | 114/469 [00:15<01:01,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 113/469, Loss: 0.4487, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▍       | 115/469 [00:15<01:00,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 114/469, Loss: 0.4482, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▍       | 116/469 [00:15<01:00,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 115/469, Loss: 0.4497, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▍       | 117/469 [00:15<00:59,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 116/469, Loss: 0.4484, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▌       | 118/469 [00:15<00:59,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 117/469, Loss: 0.4491, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▌       | 119/469 [00:15<00:59,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 118/469, Loss: 0.4492, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 120/469 [00:16<00:59,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 119/469, Loss: 0.4486, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 121/469 [00:16<00:59,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 120/469, Loss: 0.4482, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 122/469 [00:16<00:59,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 121/469, Loss: 0.4494, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 123/469 [00:16<00:58,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 122/469, Loss: 0.4476, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▋       | 124/469 [00:16<00:58,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 123/469, Loss: 0.4472, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 125/469 [00:16<00:58,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 124/469, Loss: 0.4475, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 126/469 [00:17<00:58,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 125/469, Loss: 0.4483, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 127/469 [00:17<00:58,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 126/469, Loss: 0.4480, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 128/469 [00:17<00:58,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 127/469, Loss: 0.4493, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 129/469 [00:17<00:57,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 128/469, Loss: 0.4480, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 130/469 [00:17<00:57,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 129/469, Loss: 0.4461, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 131/469 [00:17<00:57,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 130/469, Loss: 0.4475, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 132/469 [00:18<00:57,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 131/469, Loss: 0.4461, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 133/469 [00:18<00:57,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 132/469, Loss: 0.4479, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▊       | 134/469 [00:18<00:57,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 133/469, Loss: 0.4458, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 135/469 [00:18<00:57,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 134/469, Loss: 0.4477, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 136/469 [00:18<00:57,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 135/469, Loss: 0.4474, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 137/469 [00:18<00:56,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 136/469, Loss: 0.4478, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 138/469 [00:19<00:56,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 137/469, Loss: 0.4442, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|██▉       | 139/469 [00:19<00:56,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 138/469, Loss: 0.4460, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|██▉       | 140/469 [00:19<00:56,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 139/469, Loss: 0.4466, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|███       | 141/469 [00:19<00:56,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 140/469, Loss: 0.4453, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|███       | 142/469 [00:19<00:57,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 141/469, Loss: 0.4454, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|███       | 143/469 [00:19<00:56,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 142/469, Loss: 0.4450, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███       | 144/469 [00:20<00:55,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 143/469, Loss: 0.4447, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███       | 145/469 [00:20<00:55,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 144/469, Loss: 0.4443, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███       | 146/469 [00:20<00:54,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 145/469, Loss: 0.4434, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███▏      | 147/469 [00:20<00:54,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 146/469, Loss: 0.4435, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 148/469 [00:20<00:54,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 147/469, Loss: 0.4453, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 149/469 [00:20<00:54,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 148/469, Loss: 0.4446, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 150/469 [00:21<00:53,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 149/469, Loss: 0.4431, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 151/469 [00:21<00:53,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 150/469, Loss: 0.4449, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 152/469 [00:21<00:53,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 151/469, Loss: 0.4454, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 153/469 [00:21<00:53,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 152/469, Loss: 0.4450, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 154/469 [00:21<00:53,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 153/469, Loss: 0.4441, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 155/469 [00:22<00:53,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 154/469, Loss: 0.4434, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 156/469 [00:22<00:53,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 155/469, Loss: 0.4447, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 157/469 [00:22<00:53,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 156/469, Loss: 0.4428, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▎      | 158/469 [00:22<00:52,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 157/469, Loss: 0.4419, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 159/469 [00:22<00:52,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 158/469, Loss: 0.4436, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 160/469 [00:22<00:52,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 159/469, Loss: 0.4427, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 161/469 [00:23<00:52,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 160/469, Loss: 0.4422, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▍      | 162/469 [00:23<00:51,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 161/469, Loss: 0.4431, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▍      | 163/469 [00:23<00:51,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 162/469, Loss: 0.4437, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▍      | 164/469 [00:23<00:52,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 163/469, Loss: 0.4423, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▌      | 165/469 [00:23<00:51,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 164/469, Loss: 0.4423, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▌      | 166/469 [00:23<00:51,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 165/469, Loss: 0.4429, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 167/469 [00:24<00:51,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 166/469, Loss: 0.4426, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 168/469 [00:24<00:51,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 167/469, Loss: 0.4420, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 169/469 [00:24<00:51,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 168/469, Loss: 0.4422, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 170/469 [00:24<00:50,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 169/469, Loss: 0.4413, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▋      | 171/469 [00:24<00:50,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 170/469, Loss: 0.4402, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 172/469 [00:24<00:50,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 171/469, Loss: 0.4428, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 173/469 [00:25<00:50,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 172/469, Loss: 0.4410, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 174/469 [00:25<00:50,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 173/469, Loss: 0.4413, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 175/469 [00:25<00:50,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 174/469, Loss: 0.4412, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 176/469 [00:25<00:49,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 175/469, Loss: 0.4406, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 177/469 [00:25<00:49,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 176/469, Loss: 0.4424, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 178/469 [00:25<00:49,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 177/469, Loss: 0.4406, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 179/469 [00:26<00:49,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 178/469, Loss: 0.4422, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 180/469 [00:26<00:50,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 179/469, Loss: 0.4409, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▊      | 181/469 [00:26<00:51,  5.57it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 180/469, Loss: 0.4399, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 182/469 [00:26<00:51,  5.59it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 181/469, Loss: 0.4409, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 183/469 [00:26<00:50,  5.66it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 182/469, Loss: 0.4397, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 184/469 [00:26<00:50,  5.66it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 183/469, Loss: 0.4401, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 185/469 [00:27<00:49,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 184/469, Loss: 0.4395, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|███▉      | 186/469 [00:27<00:49,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 185/469, Loss: 0.4398, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|███▉      | 187/469 [00:27<00:49,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 186/469, Loss: 0.4395, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|████      | 188/469 [00:27<00:48,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 187/469, Loss: 0.4404, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|████      | 189/469 [00:27<00:48,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 188/469, Loss: 0.4392, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 190/469 [00:28<00:47,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 189/469, Loss: 0.4403, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 191/469 [00:28<00:47,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 190/469, Loss: 0.4396, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 192/469 [00:28<00:46,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 191/469, Loss: 0.4396, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 193/469 [00:28<00:46,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 192/469, Loss: 0.4396, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████▏     | 194/469 [00:28<00:46,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 193/469, Loss: 0.4384, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 195/469 [00:28<00:46,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 194/469, Loss: 0.4401, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 196/469 [00:29<00:46,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 195/469, Loss: 0.4394, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 197/469 [00:29<00:45,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 196/469, Loss: 0.4390, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 198/469 [00:29<00:45,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 197/469, Loss: 0.4393, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 199/469 [00:29<00:45,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 198/469, Loss: 0.4394, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 200/469 [00:29<00:45,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 199/469, Loss: 0.4397, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 201/469 [00:29<00:45,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 200/469, Loss: 0.4389, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 202/469 [00:30<00:45,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 201/469, Loss: 0.4374, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 203/469 [00:30<00:45,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 202/469, Loss: 0.4389, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 204/469 [00:30<00:44,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 203/469, Loss: 0.4384, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▎     | 205/469 [00:30<00:44,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 204/469, Loss: 0.4375, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▍     | 206/469 [00:30<00:44,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 205/469, Loss: 0.4370, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▍     | 207/469 [00:30<00:44,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 206/469, Loss: 0.4378, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▍     | 208/469 [00:31<00:43,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 207/469, Loss: 0.4363, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▍     | 209/469 [00:31<00:43,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 208/469, Loss: 0.4373, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▍     | 210/469 [00:31<00:43,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 209/469, Loss: 0.4361, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▍     | 211/469 [00:31<00:43,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 210/469, Loss: 0.4372, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▌     | 212/469 [00:31<00:43,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 211/469, Loss: 0.4373, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▌     | 213/469 [00:31<00:43,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 212/469, Loss: 0.4360, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▌     | 214/469 [00:32<00:42,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 213/469, Loss: 0.4376, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▌     | 215/469 [00:32<00:42,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 214/469, Loss: 0.4375, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▌     | 216/469 [00:32<00:42,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 215/469, Loss: 0.4359, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▋     | 217/469 [00:32<00:42,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 216/469, Loss: 0.4348, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▋     | 218/469 [00:32<00:42,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 217/469, Loss: 0.4360, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 219/469 [00:32<00:42,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 218/469, Loss: 0.4368, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 220/469 [00:33<00:42,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 219/469, Loss: 0.4363, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 221/469 [00:33<00:42,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 220/469, Loss: 0.4366, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 222/469 [00:33<00:42,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 221/469, Loss: 0.4362, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 223/469 [00:33<00:41,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 222/469, Loss: 0.4374, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 224/469 [00:33<00:41,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 223/469, Loss: 0.4356, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 225/469 [00:33<00:41,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 224/469, Loss: 0.4349, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 226/469 [00:34<00:41,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 225/469, Loss: 0.4353, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 227/469 [00:34<00:41,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 226/469, Loss: 0.4360, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▊     | 228/469 [00:34<00:41,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 227/469, Loss: 0.4352, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 229/469 [00:34<00:41,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 228/469, Loss: 0.4344, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 230/469 [00:34<00:40,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 229/469, Loss: 0.4355, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 231/469 [00:34<00:41,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 230/469, Loss: 0.4352, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 232/469 [00:35<00:41,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 231/469, Loss: 0.4340, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|████▉     | 233/469 [00:35<00:40,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 232/469, Loss: 0.4336, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|████▉     | 234/469 [00:35<00:40,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 233/469, Loss: 0.4331, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|█████     | 235/469 [00:35<00:40,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 234/469, Loss: 0.4338, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|█████     | 236/469 [00:35<00:40,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 235/469, Loss: 0.4343, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 237/469 [00:36<00:39,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 236/469, Loss: 0.4339, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 238/469 [00:36<00:39,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 237/469, Loss: 0.4332, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 239/469 [00:36<00:39,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 238/469, Loss: 0.4337, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 240/469 [00:36<00:39,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 239/469, Loss: 0.4322, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████▏    | 241/469 [00:36<00:39,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 240/469, Loss: 0.4332, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 242/469 [00:36<00:39,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 241/469, Loss: 0.4325, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 243/469 [00:37<00:38,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 242/469, Loss: 0.4339, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 244/469 [00:37<00:38,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 243/469, Loss: 0.4353, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 245/469 [00:37<00:38,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 244/469, Loss: 0.4322, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 246/469 [00:37<00:38,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 245/469, Loss: 0.4329, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 247/469 [00:37<00:38,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 246/469, Loss: 0.4321, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 248/469 [00:37<00:38,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 247/469, Loss: 0.4335, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 249/469 [00:38<00:38,  5.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 248/469, Loss: 0.4324, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 250/469 [00:38<00:38,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 249/469, Loss: 0.4325, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▎    | 251/469 [00:38<00:38,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 250/469, Loss: 0.4334, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▎    | 252/469 [00:38<00:37,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 251/469, Loss: 0.4324, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▍    | 253/469 [00:38<00:38,  5.65it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 252/469, Loss: 0.4312, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▍    | 254/469 [00:38<00:37,  5.66it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 253/469, Loss: 0.4317, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▍    | 255/469 [00:39<00:37,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 254/469, Loss: 0.4322, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▍    | 256/469 [00:39<00:37,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 255/469, Loss: 0.4317, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▍    | 257/469 [00:39<00:36,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 256/469, Loss: 0.4298, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▌    | 258/469 [00:39<00:36,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 257/469, Loss: 0.4312, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▌    | 259/469 [00:39<00:36,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 258/469, Loss: 0.4311, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▌    | 260/469 [00:40<00:36,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 259/469, Loss: 0.4314, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▌    | 261/469 [00:40<00:35,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 260/469, Loss: 0.4308, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▌    | 262/469 [00:40<00:36,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 261/469, Loss: 0.4310, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▌    | 263/469 [00:40<00:35,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 262/469, Loss: 0.4293, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▋    | 264/469 [00:40<00:35,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 263/469, Loss: 0.4293, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 265/469 [00:40<00:35,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 264/469, Loss: 0.4306, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 266/469 [00:41<00:35,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 265/469, Loss: 0.4288, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 267/469 [00:41<00:35,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 266/469, Loss: 0.4295, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 268/469 [00:41<00:34,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 267/469, Loss: 0.4294, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 269/469 [00:41<00:34,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 268/469, Loss: 0.4296, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 270/469 [00:41<00:34,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 269/469, Loss: 0.4306, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 271/469 [00:41<00:34,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 270/469, Loss: 0.4296, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 272/469 [00:42<00:34,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 271/469, Loss: 0.4295, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 273/469 [00:42<00:33,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 272/469, Loss: 0.4289, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 274/469 [00:42<00:33,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 273/469, Loss: 0.4292, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▊    | 275/469 [00:42<00:33,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 274/469, Loss: 0.4290, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 276/469 [00:42<00:33,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 275/469, Loss: 0.4289, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 277/469 [00:42<00:33,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 276/469, Loss: 0.4282, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 278/469 [00:43<00:33,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 277/469, Loss: 0.4295, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 279/469 [00:43<00:33,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 278/469, Loss: 0.4288, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|█████▉    | 280/469 [00:43<00:33,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 279/469, Loss: 0.4274, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|█████▉    | 281/469 [00:43<00:32,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 280/469, Loss: 0.4277, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|██████    | 282/469 [00:43<00:32,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 281/469, Loss: 0.4284, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|██████    | 283/469 [00:44<00:32,  5.67it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 282/469, Loss: 0.4274, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 284/469 [00:44<00:32,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 283/469, Loss: 0.4290, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 285/469 [00:44<00:32,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 284/469, Loss: 0.4268, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 286/469 [00:44<00:31,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 285/469, Loss: 0.4279, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 287/469 [00:44<00:31,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 286/469, Loss: 0.4284, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████▏   | 288/469 [00:44<00:31,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 287/469, Loss: 0.4278, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 289/469 [00:45<00:31,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 288/469, Loss: 0.4268, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 290/469 [00:45<00:30,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 289/469, Loss: 0.4270, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 291/469 [00:45<00:30,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 290/469, Loss: 0.4263, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 292/469 [00:45<00:30,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 291/469, Loss: 0.4280, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 293/469 [00:45<00:30,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 292/469, Loss: 0.4263, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 294/469 [00:45<00:29,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 293/469, Loss: 0.4267, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 295/469 [00:46<00:29,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 294/469, Loss: 0.4262, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 296/469 [00:46<00:29,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 295/469, Loss: 0.4242, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 297/469 [00:46<00:29,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 296/469, Loss: 0.4261, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▎   | 298/469 [00:46<00:29,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 297/469, Loss: 0.4255, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 299/469 [00:46<00:29,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 298/469, Loss: 0.4265, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 300/469 [00:46<00:28,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 299/469, Loss: 0.4257, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 301/469 [00:47<00:28,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 300/469, Loss: 0.4252, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 302/469 [00:47<00:28,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 301/469, Loss: 0.4255, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▍   | 303/469 [00:47<00:28,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 302/469, Loss: 0.4252, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▍   | 304/469 [00:47<00:27,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 303/469, Loss: 0.4247, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▌   | 305/469 [00:47<00:27,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 304/469, Loss: 0.4246, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▌   | 306/469 [00:47<00:27,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 305/469, Loss: 0.4260, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▌   | 307/469 [00:48<00:27,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 306/469, Loss: 0.4257, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▌   | 308/469 [00:48<00:27,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 307/469, Loss: 0.4235, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▌   | 309/469 [00:48<00:27,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 308/469, Loss: 0.4248, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▌   | 310/469 [00:48<00:27,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 309/469, Loss: 0.4248, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▋   | 311/469 [00:48<00:27,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 310/469, Loss: 0.4246, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 312/469 [00:48<00:26,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 311/469, Loss: 0.4246, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 313/469 [00:49<00:26,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 312/469, Loss: 0.4249, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 314/469 [00:49<00:26,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 313/469, Loss: 0.4230, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 315/469 [00:49<00:26,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 314/469, Loss: 0.4236, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 316/469 [00:49<00:26,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 315/469, Loss: 0.4230, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 317/469 [00:49<00:26,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 316/469, Loss: 0.4240, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 318/469 [00:50<00:26,  5.66it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 317/469, Loss: 0.4236, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 319/469 [00:50<00:26,  5.62it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 318/469, Loss: 0.4227, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 320/469 [00:50<00:26,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 319/469, Loss: 0.4241, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 321/469 [00:50<00:25,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 320/469, Loss: 0.4233, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  69%|██████▊   | 322/469 [00:50<00:25,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 321/469, Loss: 0.4223, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  69%|██████▉   | 323/469 [00:50<00:25,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 322/469, Loss: 0.4232, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  69%|██████▉   | 324/469 [00:51<00:24,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 323/469, Loss: 0.4242, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  69%|██████▉   | 325/469 [00:51<00:24,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 324/469, Loss: 0.4220, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  70%|██████▉   | 326/469 [00:51<00:24,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 325/469, Loss: 0.4220, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  70%|██████▉   | 327/469 [00:51<00:23,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 326/469, Loss: 0.4214, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  70%|██████▉   | 328/469 [00:51<00:23,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 327/469, Loss: 0.4241, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  70%|███████   | 329/469 [00:51<00:23,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 328/469, Loss: 0.4213, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  70%|███████   | 330/469 [00:52<00:23,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 329/469, Loss: 0.4228, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  71%|███████   | 331/469 [00:52<00:23,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 330/469, Loss: 0.4214, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  71%|███████   | 332/469 [00:52<00:23,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 331/469, Loss: 0.4221, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  71%|███████   | 333/469 [00:52<00:23,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 332/469, Loss: 0.4214, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  71%|███████   | 334/469 [00:52<00:23,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 333/469, Loss: 0.4221, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  71%|███████▏  | 335/469 [00:52<00:22,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 334/469, Loss: 0.4210, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  72%|███████▏  | 336/469 [00:53<00:22,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 335/469, Loss: 0.4201, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  72%|███████▏  | 337/469 [00:53<00:22,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 336/469, Loss: 0.4201, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  72%|███████▏  | 338/469 [00:53<00:21,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 337/469, Loss: 0.4221, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  72%|███████▏  | 339/469 [00:53<00:21,  5.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 338/469, Loss: 0.4216, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  72%|███████▏  | 340/469 [00:53<00:21,  5.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 339/469, Loss: 0.4205, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  73%|███████▎  | 341/469 [00:53<00:21,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 340/469, Loss: 0.4205, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  73%|███████▎  | 342/469 [00:54<00:21,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 341/469, Loss: 0.4212, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  73%|███████▎  | 343/469 [00:54<00:21,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 342/469, Loss: 0.4207, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  73%|███████▎  | 344/469 [00:54<00:21,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 343/469, Loss: 0.4199, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  74%|███████▎  | 345/469 [00:54<00:20,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 344/469, Loss: 0.4212, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  74%|███████▍  | 346/469 [00:54<00:20,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 345/469, Loss: 0.4199, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  74%|███████▍  | 347/469 [00:54<00:20,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 346/469, Loss: 0.4202, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  74%|███████▍  | 348/469 [00:55<00:20,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 347/469, Loss: 0.4201, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  74%|███████▍  | 349/469 [00:55<00:20,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 348/469, Loss: 0.4211, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  75%|███████▍  | 350/469 [00:55<00:20,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 349/469, Loss: 0.4205, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  75%|███████▍  | 351/469 [00:55<00:20,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 350/469, Loss: 0.4207, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  75%|███████▌  | 352/469 [00:55<00:19,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 351/469, Loss: 0.4191, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  75%|███████▌  | 353/469 [00:55<00:19,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 352/469, Loss: 0.4198, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  75%|███████▌  | 354/469 [00:56<00:19,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 353/469, Loss: 0.4205, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  76%|███████▌  | 355/469 [00:56<00:19,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 354/469, Loss: 0.4183, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  76%|███████▌  | 356/469 [00:56<00:19,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 355/469, Loss: 0.4200, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  76%|███████▌  | 357/469 [00:56<00:19,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 356/469, Loss: 0.4174, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  76%|███████▋  | 358/469 [00:56<00:18,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 357/469, Loss: 0.4179, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  77%|███████▋  | 359/469 [00:56<00:18,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 358/469, Loss: 0.4184, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  77%|███████▋  | 360/469 [00:57<00:18,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 359/469, Loss: 0.4178, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  77%|███████▋  | 361/469 [00:57<00:18,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 360/469, Loss: 0.4189, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  77%|███████▋  | 362/469 [00:57<00:18,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 361/469, Loss: 0.4171, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  77%|███████▋  | 363/469 [00:57<00:18,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 362/469, Loss: 0.4187, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  78%|███████▊  | 364/469 [00:57<00:17,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 363/469, Loss: 0.4177, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  78%|███████▊  | 365/469 [00:57<00:17,  5.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 364/469, Loss: 0.4175, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  78%|███████▊  | 366/469 [00:58<00:17,  6.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 365/469, Loss: 0.4189, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  78%|███████▊  | 367/469 [00:58<00:17,  6.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 366/469, Loss: 0.4164, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  78%|███████▊  | 368/469 [00:58<00:16,  5.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 367/469, Loss: 0.4179, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  79%|███████▊  | 369/469 [00:58<00:16,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 368/469, Loss: 0.4174, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  79%|███████▉  | 370/469 [00:58<00:16,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 369/469, Loss: 0.4186, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  79%|███████▉  | 371/469 [00:59<00:16,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 370/469, Loss: 0.4168, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  79%|███████▉  | 372/469 [00:59<00:16,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 371/469, Loss: 0.4173, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  80%|███████▉  | 373/469 [00:59<00:16,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 372/469, Loss: 0.4166, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  80%|███████▉  | 374/469 [00:59<00:16,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 373/469, Loss: 0.4158, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  80%|███████▉  | 375/469 [00:59<00:15,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 374/469, Loss: 0.4155, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  80%|████████  | 376/469 [00:59<00:15,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 375/469, Loss: 0.4166, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  80%|████████  | 377/469 [01:00<00:15,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 376/469, Loss: 0.4161, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  81%|████████  | 378/469 [01:00<00:15,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 377/469, Loss: 0.4157, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  81%|████████  | 379/469 [01:00<00:15,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 378/469, Loss: 0.4160, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  81%|████████  | 380/469 [01:00<00:15,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 379/469, Loss: 0.4153, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  81%|████████  | 381/469 [01:00<00:15,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 380/469, Loss: 0.4171, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  81%|████████▏ | 382/469 [01:00<00:15,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 381/469, Loss: 0.4147, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  82%|████████▏ | 383/469 [01:01<00:14,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 382/469, Loss: 0.4152, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  82%|████████▏ | 384/469 [01:01<00:14,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 383/469, Loss: 0.4155, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  82%|████████▏ | 385/469 [01:01<00:14,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 384/469, Loss: 0.4156, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  82%|████████▏ | 386/469 [01:01<00:14,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 385/469, Loss: 0.4164, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  83%|████████▎ | 387/469 [01:01<00:14,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 386/469, Loss: 0.4152, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  83%|████████▎ | 388/469 [01:01<00:14,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 387/469, Loss: 0.4154, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  83%|████████▎ | 389/469 [01:02<00:14,  5.69it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 388/469, Loss: 0.4153, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  83%|████████▎ | 390/469 [01:02<00:13,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 389/469, Loss: 0.4150, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  83%|████████▎ | 391/469 [01:02<00:13,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 390/469, Loss: 0.4142, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  84%|████████▎ | 392/469 [01:02<00:13,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 391/469, Loss: 0.4147, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  84%|████████▍ | 393/469 [01:02<00:13,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 392/469, Loss: 0.4134, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  84%|████████▍ | 394/469 [01:02<00:13,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 393/469, Loss: 0.4163, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  84%|████████▍ | 395/469 [01:03<00:12,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 394/469, Loss: 0.4138, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  84%|████████▍ | 396/469 [01:03<00:12,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 395/469, Loss: 0.4132, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  85%|████████▍ | 397/469 [01:03<00:12,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 396/469, Loss: 0.4138, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  85%|████████▍ | 398/469 [01:03<00:12,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 397/469, Loss: 0.4143, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  85%|████████▌ | 399/469 [01:03<00:12,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 398/469, Loss: 0.4125, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  85%|████████▌ | 400/469 [01:04<00:12,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 399/469, Loss: 0.4149, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  86%|████████▌ | 401/469 [01:04<00:11,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 400/469, Loss: 0.4133, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  86%|████████▌ | 402/469 [01:04<00:11,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 401/469, Loss: 0.4125, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  86%|████████▌ | 403/469 [01:04<00:11,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 402/469, Loss: 0.4130, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  86%|████████▌ | 404/469 [01:04<00:11,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 403/469, Loss: 0.4117, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  86%|████████▋ | 405/469 [01:04<00:11,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 404/469, Loss: 0.4113, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  87%|████████▋ | 406/469 [01:05<00:10,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 405/469, Loss: 0.4137, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  87%|████████▋ | 407/469 [01:05<00:10,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 406/469, Loss: 0.4129, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  87%|████████▋ | 408/469 [01:05<00:10,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 407/469, Loss: 0.4120, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  87%|████████▋ | 409/469 [01:05<00:10,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 408/469, Loss: 0.4129, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  87%|████████▋ | 410/469 [01:05<00:10,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 409/469, Loss: 0.4110, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  88%|████████▊ | 411/469 [01:05<00:10,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 410/469, Loss: 0.4119, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  88%|████████▊ | 412/469 [01:06<00:09,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 411/469, Loss: 0.4124, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  88%|████████▊ | 413/469 [01:06<00:09,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 412/469, Loss: 0.4122, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  88%|████████▊ | 414/469 [01:06<00:09,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 413/469, Loss: 0.4118, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  88%|████████▊ | 415/469 [01:06<00:09,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 414/469, Loss: 0.4109, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  89%|████████▊ | 416/469 [01:06<00:08,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 415/469, Loss: 0.4112, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  89%|████████▉ | 417/469 [01:06<00:08,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 416/469, Loss: 0.4104, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  89%|████████▉ | 418/469 [01:07<00:08,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 417/469, Loss: 0.4123, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  89%|████████▉ | 419/469 [01:07<00:08,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 418/469, Loss: 0.4103, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  90%|████████▉ | 420/469 [01:07<00:08,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 419/469, Loss: 0.4104, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  90%|████████▉ | 421/469 [01:07<00:08,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 420/469, Loss: 0.4105, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  90%|████████▉ | 422/469 [01:07<00:08,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 421/469, Loss: 0.4101, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  90%|█████████ | 423/469 [01:07<00:07,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 422/469, Loss: 0.4105, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  90%|█████████ | 424/469 [01:08<00:07,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 423/469, Loss: 0.4111, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  91%|█████████ | 425/469 [01:08<00:07,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 424/469, Loss: 0.4112, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  91%|█████████ | 426/469 [01:08<00:07,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 425/469, Loss: 0.4104, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  91%|█████████ | 427/469 [01:08<00:07,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 426/469, Loss: 0.4106, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  91%|█████████▏| 428/469 [01:08<00:06,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 427/469, Loss: 0.4101, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  91%|█████████▏| 429/469 [01:08<00:06,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 428/469, Loss: 0.4102, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  92%|█████████▏| 430/469 [01:09<00:06,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 429/469, Loss: 0.4088, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  92%|█████████▏| 431/469 [01:09<00:06,  6.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 430/469, Loss: 0.4088, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  92%|█████████▏| 432/469 [01:09<00:06,  6.00it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 431/469, Loss: 0.4103, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  92%|█████████▏| 433/469 [01:09<00:06,  5.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 432/469, Loss: 0.4108, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  93%|█████████▎| 434/469 [01:09<00:05,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 433/469, Loss: 0.4088, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  93%|█████████▎| 435/469 [01:09<00:05,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 434/469, Loss: 0.4094, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  93%|█████████▎| 436/469 [01:10<00:05,  5.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 435/469, Loss: 0.4090, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  93%|█████████▎| 437/469 [01:10<00:05,  5.98it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 436/469, Loss: 0.4099, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  93%|█████████▎| 438/469 [01:10<00:05,  5.99it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 437/469, Loss: 0.4073, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  94%|█████████▎| 439/469 [01:10<00:05,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 438/469, Loss: 0.4079, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  94%|█████████▍| 440/469 [01:10<00:04,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 439/469, Loss: 0.4074, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  94%|█████████▍| 441/469 [01:10<00:04,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 440/469, Loss: 0.4072, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  94%|█████████▍| 442/469 [01:11<00:04,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 441/469, Loss: 0.4065, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  94%|█████████▍| 443/469 [01:11<00:04,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 442/469, Loss: 0.4068, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  95%|█████████▍| 444/469 [01:11<00:04,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 443/469, Loss: 0.4071, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  95%|█████████▍| 445/469 [01:11<00:04,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 444/469, Loss: 0.4083, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  95%|█████████▌| 446/469 [01:11<00:03,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 445/469, Loss: 0.4083, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  95%|█████████▌| 447/469 [01:12<00:03,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 446/469, Loss: 0.4064, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  96%|█████████▌| 448/469 [01:12<00:03,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 447/469, Loss: 0.4078, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  96%|█████████▌| 449/469 [01:12<00:03,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 448/469, Loss: 0.4061, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  96%|█████████▌| 450/469 [01:12<00:03,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 449/469, Loss: 0.4074, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  96%|█████████▌| 451/469 [01:12<00:03,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 450/469, Loss: 0.4083, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  96%|█████████▋| 452/469 [01:12<00:02,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 451/469, Loss: 0.4086, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  97%|█████████▋| 453/469 [01:13<00:02,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 452/469, Loss: 0.4071, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  97%|█████████▋| 454/469 [01:13<00:02,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 453/469, Loss: 0.4062, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  97%|█████████▋| 455/469 [01:13<00:02,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 454/469, Loss: 0.4055, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  97%|█████████▋| 456/469 [01:13<00:02,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 455/469, Loss: 0.4073, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  97%|█████████▋| 457/469 [01:13<00:02,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 456/469, Loss: 0.4071, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  98%|█████████▊| 458/469 [01:13<00:01,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 457/469, Loss: 0.4074, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  98%|█████████▊| 459/469 [01:14<00:01,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 458/469, Loss: 0.4063, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  98%|█████████▊| 460/469 [01:14<00:01,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 459/469, Loss: 0.4061, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  98%|█████████▊| 461/469 [01:14<00:01,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 460/469, Loss: 0.4070, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  99%|█████████▊| 462/469 [01:14<00:01,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 461/469, Loss: 0.4057, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  99%|█████████▊| 463/469 [01:14<00:01,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 462/469, Loss: 0.4058, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  99%|█████████▉| 464/469 [01:14<00:00,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 463/469, Loss: 0.4055, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  99%|█████████▉| 465/469 [01:15<00:00,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 464/469, Loss: 0.4044, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  99%|█████████▉| 466/469 [01:15<00:00,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 465/469, Loss: 0.4053, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|█████████▉| 467/469 [01:15<00:00,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 466/469, Loss: 0.4054, LR: 0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|█████████▉| 468/469 [01:15<00:00,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Batch 467/469, Loss: 0.4054, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training: 100%|██████████| 469/469 [01:15<00:00,  5.88it/s]\u001b[A\n",
            "Epochs:  20%|██        | 1/5 [01:15<05:03, 75.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 468/469, Loss: 0.4082, LR: 0.000000\n",
            "Epoch 1/5 loss: 0.434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 1/469 [00:00<01:19,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 0/469, Loss: 0.4050, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   0%|          | 2/469 [00:00<01:19,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 1/469, Loss: 0.4041, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|          | 3/469 [00:00<01:18,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 2/469, Loss: 0.4046, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|          | 4/469 [00:00<01:18,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 3/469, Loss: 0.4042, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|          | 5/469 [00:00<01:18,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 4/469, Loss: 0.4059, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|▏         | 6/469 [00:01<01:18,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 5/469, Loss: 0.4043, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   1%|▏         | 7/469 [00:01<01:18,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 6/469, Loss: 0.4042, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 8/469 [00:01<01:18,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 7/469, Loss: 0.4045, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 9/469 [00:01<01:18,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 8/469, Loss: 0.4040, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 10/469 [00:01<01:17,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 9/469, Loss: 0.4035, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   2%|▏         | 11/469 [00:01<01:17,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 10/469, Loss: 0.4034, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 12/469 [00:02<01:18,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 11/469, Loss: 0.4031, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 13/469 [00:02<01:18,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 12/469, Loss: 0.4045, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 14/469 [00:02<01:18,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 13/469, Loss: 0.4032, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 15/469 [00:02<01:18,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 14/469, Loss: 0.4029, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   3%|▎         | 16/469 [00:02<01:17,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 15/469, Loss: 0.4012, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▎         | 17/469 [00:02<01:17,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 16/469, Loss: 0.4011, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 18/469 [00:03<01:16,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 17/469, Loss: 0.4011, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 19/469 [00:03<01:16,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 18/469, Loss: 0.4035, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 20/469 [00:03<01:17,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 19/469, Loss: 0.4020, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   4%|▍         | 21/469 [00:03<01:17,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 20/469, Loss: 0.4027, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▍         | 22/469 [00:03<01:17,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 21/469, Loss: 0.4016, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▍         | 23/469 [00:03<01:17,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 22/469, Loss: 0.4021, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▌         | 24/469 [00:04<01:16,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 23/469, Loss: 0.4011, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   5%|▌         | 25/469 [00:04<01:15,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 24/469, Loss: 0.4016, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 26/469 [00:04<01:15,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 25/469, Loss: 0.4029, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 27/469 [00:04<01:14,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 26/469, Loss: 0.4036, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 28/469 [00:04<01:14,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 27/469, Loss: 0.4022, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▌         | 29/469 [00:04<01:14,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 28/469, Loss: 0.4002, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   6%|▋         | 30/469 [00:05<01:14,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 29/469, Loss: 0.4014, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 31/469 [00:05<01:13,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 30/469, Loss: 0.4020, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 32/469 [00:05<01:13,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 31/469, Loss: 0.4005, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 33/469 [00:05<01:13,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 32/469, Loss: 0.4007, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 34/469 [00:05<01:13,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 33/469, Loss: 0.4019, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   7%|▋         | 35/469 [00:05<01:12,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 34/469, Loss: 0.4017, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 36/469 [00:06<01:12,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 35/469, Loss: 0.3998, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 37/469 [00:06<01:12,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 36/469, Loss: 0.4003, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 38/469 [00:06<01:12,  5.97it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 37/469, Loss: 0.3998, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   8%|▊         | 39/469 [00:06<01:12,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 38/469, Loss: 0.4001, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▊         | 40/469 [00:06<01:11,  5.96it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 39/469, Loss: 0.3995, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▊         | 41/469 [00:06<01:11,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 40/469, Loss: 0.4003, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▉         | 42/469 [00:07<01:12,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 41/469, Loss: 0.4004, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▉         | 43/469 [00:07<01:12,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 42/469, Loss: 0.3985, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:   9%|▉         | 44/469 [00:07<01:11,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 43/469, Loss: 0.4001, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|▉         | 45/469 [00:07<01:11,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 44/469, Loss: 0.4006, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|▉         | 46/469 [00:07<01:11,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 45/469, Loss: 0.3988, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|█         | 47/469 [00:07<01:11,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 46/469, Loss: 0.3978, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|█         | 48/469 [00:08<01:13,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 47/469, Loss: 0.3994, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  10%|█         | 49/469 [00:08<01:14,  5.66it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 48/469, Loss: 0.3995, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█         | 50/469 [00:08<01:13,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 49/469, Loss: 0.3978, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█         | 51/469 [00:08<01:14,  5.58it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 50/469, Loss: 0.3971, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█         | 52/469 [00:08<01:13,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 51/469, Loss: 0.3980, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  11%|█▏        | 53/469 [00:09<01:12,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 52/469, Loss: 0.3974, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 54/469 [00:09<01:11,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 53/469, Loss: 0.3984, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 55/469 [00:09<01:11,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 54/469, Loss: 0.3983, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 56/469 [00:09<01:11,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 55/469, Loss: 0.3989, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 57/469 [00:09<01:11,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 56/469, Loss: 0.3982, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  12%|█▏        | 58/469 [00:09<01:11,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 57/469, Loss: 0.3979, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 59/469 [00:10<01:11,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 58/469, Loss: 0.3984, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 60/469 [00:10<01:10,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 59/469, Loss: 0.3963, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 61/469 [00:10<01:10,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 60/469, Loss: 0.3971, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 62/469 [00:10<01:09,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 61/469, Loss: 0.3966, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  13%|█▎        | 63/469 [00:10<01:09,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 62/469, Loss: 0.3981, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▎        | 64/469 [00:10<01:08,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 63/469, Loss: 0.3963, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 65/469 [00:11<01:08,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 64/469, Loss: 0.3965, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 66/469 [00:11<01:08,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 65/469, Loss: 0.3993, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 67/469 [00:11<01:08,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 66/469, Loss: 0.3971, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  14%|█▍        | 68/469 [00:11<01:07,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 67/469, Loss: 0.3971, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▍        | 69/469 [00:11<01:07,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 68/469, Loss: 0.3946, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▍        | 70/469 [00:11<01:07,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 69/469, Loss: 0.3954, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▌        | 71/469 [00:12<01:07,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 70/469, Loss: 0.3957, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  15%|█▌        | 72/469 [00:12<01:07,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 71/469, Loss: 0.3959, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 73/469 [00:12<01:06,  5.94it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 72/469, Loss: 0.3959, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 74/469 [00:12<01:06,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 73/469, Loss: 0.3972, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 75/469 [00:12<01:06,  5.95it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 74/469, Loss: 0.3958, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▌        | 76/469 [00:12<01:06,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 75/469, Loss: 0.3944, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  16%|█▋        | 77/469 [00:13<01:06,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 76/469, Loss: 0.3962, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 78/469 [00:13<01:06,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 77/469, Loss: 0.3947, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 79/469 [00:13<01:05,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 78/469, Loss: 0.3945, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 80/469 [00:13<01:05,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 79/469, Loss: 0.3949, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 81/469 [00:13<01:05,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 80/469, Loss: 0.3963, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  17%|█▋        | 82/469 [00:13<01:05,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 81/469, Loss: 0.3950, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 83/469 [00:14<01:06,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 82/469, Loss: 0.3955, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 84/469 [00:14<01:06,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 83/469, Loss: 0.3948, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 85/469 [00:14<01:06,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 84/469, Loss: 0.3956, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  18%|█▊        | 86/469 [00:14<01:06,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 85/469, Loss: 0.3943, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▊        | 87/469 [00:14<01:05,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 86/469, Loss: 0.3952, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 88/469 [00:15<01:05,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 87/469, Loss: 0.3935, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 89/469 [00:15<01:04,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 88/469, Loss: 0.3946, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 90/469 [00:15<01:04,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 89/469, Loss: 0.3950, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  19%|█▉        | 91/469 [00:15<01:04,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 90/469, Loss: 0.3927, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|█▉        | 92/469 [00:15<01:04,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 91/469, Loss: 0.3927, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|█▉        | 93/469 [00:15<01:04,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 92/469, Loss: 0.3913, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|██        | 94/469 [00:16<01:04,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 93/469, Loss: 0.3952, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|██        | 95/469 [00:16<01:04,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 94/469, Loss: 0.3917, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  20%|██        | 96/469 [00:16<01:03,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 95/469, Loss: 0.3926, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██        | 97/469 [00:16<01:03,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 96/469, Loss: 0.3943, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██        | 98/469 [00:16<01:03,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 97/469, Loss: 0.3935, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██        | 99/469 [00:16<01:02,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 98/469, Loss: 0.3929, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  21%|██▏       | 100/469 [00:17<01:02,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 99/469, Loss: 0.3935, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 101/469 [00:17<01:02,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 100/469, Loss: 0.3925, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 102/469 [00:17<01:02,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 101/469, Loss: 0.3906, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 103/469 [00:17<01:02,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 102/469, Loss: 0.3912, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 104/469 [00:17<01:01,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 103/469, Loss: 0.3902, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  22%|██▏       | 105/469 [00:17<01:01,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 104/469, Loss: 0.3943, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 106/469 [00:18<01:01,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 105/469, Loss: 0.3922, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 107/469 [00:18<01:01,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 106/469, Loss: 0.3923, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 108/469 [00:18<01:01,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 107/469, Loss: 0.3943, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 109/469 [00:18<01:01,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 108/469, Loss: 0.3919, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  23%|██▎       | 110/469 [00:18<01:01,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 109/469, Loss: 0.3899, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▎       | 111/469 [00:18<01:01,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 110/469, Loss: 0.3928, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▍       | 112/469 [00:19<01:00,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 111/469, Loss: 0.3912, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▍       | 113/469 [00:19<01:00,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 112/469, Loss: 0.3917, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  24%|██▍       | 114/469 [00:19<01:00,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 113/469, Loss: 0.3896, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▍       | 115/469 [00:19<00:59,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 114/469, Loss: 0.3900, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▍       | 116/469 [00:19<00:59,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 115/469, Loss: 0.3907, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▍       | 117/469 [00:19<00:59,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 116/469, Loss: 0.3888, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▌       | 118/469 [00:20<01:00,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 117/469, Loss: 0.3899, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  25%|██▌       | 119/469 [00:20<00:59,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 118/469, Loss: 0.3891, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 120/469 [00:20<00:59,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 119/469, Loss: 0.3899, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 121/469 [00:20<01:00,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 120/469, Loss: 0.3892, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 122/469 [00:20<01:00,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 121/469, Loss: 0.3902, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▌       | 123/469 [00:20<00:59,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 122/469, Loss: 0.3900, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  26%|██▋       | 124/469 [00:21<00:59,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 123/469, Loss: 0.3889, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 125/469 [00:21<01:00,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 124/469, Loss: 0.3901, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 126/469 [00:21<01:00,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 125/469, Loss: 0.3896, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 127/469 [00:21<01:00,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 126/469, Loss: 0.3879, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  27%|██▋       | 128/469 [00:21<00:59,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 127/469, Loss: 0.3907, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 129/469 [00:22<00:58,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 128/469, Loss: 0.3906, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 130/469 [00:22<00:58,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 129/469, Loss: 0.3884, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 131/469 [00:22<00:58,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 130/469, Loss: 0.3887, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 132/469 [00:22<00:57,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 131/469, Loss: 0.3887, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  28%|██▊       | 133/469 [00:22<00:57,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 132/469, Loss: 0.3892, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▊       | 134/469 [00:22<00:57,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 133/469, Loss: 0.3885, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 135/469 [00:23<00:56,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 134/469, Loss: 0.3875, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 136/469 [00:23<00:56,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 135/469, Loss: 0.3896, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 137/469 [00:23<00:56,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 136/469, Loss: 0.3889, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  29%|██▉       | 138/469 [00:23<00:56,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 137/469, Loss: 0.3878, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|██▉       | 139/469 [00:23<00:56,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 138/469, Loss: 0.3880, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|██▉       | 140/469 [00:23<00:55,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 139/469, Loss: 0.3877, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|███       | 141/469 [00:24<00:55,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 140/469, Loss: 0.3879, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|███       | 142/469 [00:24<00:55,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 141/469, Loss: 0.3896, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  30%|███       | 143/469 [00:24<00:55,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 142/469, Loss: 0.3881, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███       | 144/469 [00:24<00:55,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 143/469, Loss: 0.3879, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███       | 145/469 [00:24<00:55,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 144/469, Loss: 0.3894, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███       | 146/469 [00:24<00:54,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 145/469, Loss: 0.3877, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  31%|███▏      | 147/469 [00:25<00:54,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 146/469, Loss: 0.3862, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 148/469 [00:25<00:54,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 147/469, Loss: 0.3874, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 149/469 [00:25<00:53,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 148/469, Loss: 0.3875, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 150/469 [00:25<00:53,  5.93it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 149/469, Loss: 0.3864, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 151/469 [00:25<00:53,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 150/469, Loss: 0.3863, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  32%|███▏      | 152/469 [00:25<00:53,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 151/469, Loss: 0.3882, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 153/469 [00:26<00:53,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 152/469, Loss: 0.3884, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 154/469 [00:26<00:54,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 153/469, Loss: 0.3885, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 155/469 [00:26<00:54,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 154/469, Loss: 0.3865, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 156/469 [00:26<00:53,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 155/469, Loss: 0.3852, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  33%|███▎      | 157/469 [00:26<00:53,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 156/469, Loss: 0.3868, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▎      | 158/469 [00:26<00:53,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 157/469, Loss: 0.3855, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 159/469 [00:27<00:53,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 158/469, Loss: 0.3846, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 160/469 [00:27<00:53,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 159/469, Loss: 0.3873, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  34%|███▍      | 161/469 [00:27<00:53,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 160/469, Loss: 0.3855, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▍      | 162/469 [00:27<00:53,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 161/469, Loss: 0.3855, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▍      | 163/469 [00:27<00:53,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 162/469, Loss: 0.3844, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▍      | 164/469 [00:28<00:53,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 163/469, Loss: 0.3860, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▌      | 165/469 [00:28<00:53,  5.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 164/469, Loss: 0.3826, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  35%|███▌      | 166/469 [00:28<00:52,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 165/469, Loss: 0.3849, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 167/469 [00:28<00:52,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 166/469, Loss: 0.3854, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 168/469 [00:28<00:52,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 167/469, Loss: 0.3842, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 169/469 [00:28<00:52,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 168/469, Loss: 0.3846, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▌      | 170/469 [00:29<00:51,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 169/469, Loss: 0.3862, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  36%|███▋      | 171/469 [00:29<00:51,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 170/469, Loss: 0.3826, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 172/469 [00:29<00:51,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 171/469, Loss: 0.3866, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 173/469 [00:29<00:51,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 172/469, Loss: 0.3861, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 174/469 [00:29<00:51,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 173/469, Loss: 0.3853, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  37%|███▋      | 175/469 [00:29<00:50,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 174/469, Loss: 0.3823, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 176/469 [00:30<00:50,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 175/469, Loss: 0.3827, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 177/469 [00:30<00:50,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 176/469, Loss: 0.3841, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 178/469 [00:30<00:50,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 177/469, Loss: 0.3840, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 179/469 [00:30<00:50,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 178/469, Loss: 0.3846, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  38%|███▊      | 180/469 [00:30<00:49,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 179/469, Loss: 0.3826, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▊      | 181/469 [00:30<00:49,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 180/469, Loss: 0.3825, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 182/469 [00:31<00:49,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 181/469, Loss: 0.3815, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 183/469 [00:31<00:49,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 182/469, Loss: 0.3827, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 184/469 [00:31<00:48,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 183/469, Loss: 0.3829, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  39%|███▉      | 185/469 [00:31<00:48,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 184/469, Loss: 0.3809, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|███▉      | 186/469 [00:31<00:48,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 185/469, Loss: 0.3820, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|███▉      | 187/469 [00:32<00:48,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 186/469, Loss: 0.3816, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|████      | 188/469 [00:32<00:48,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 187/469, Loss: 0.3824, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  40%|████      | 189/469 [00:32<00:49,  5.69it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 188/469, Loss: 0.3821, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 190/469 [00:32<00:48,  5.72it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 189/469, Loss: 0.3821, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 191/469 [00:32<00:48,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 190/469, Loss: 0.3815, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 192/469 [00:32<00:48,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 191/469, Loss: 0.3812, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████      | 193/469 [00:33<00:48,  5.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 192/469, Loss: 0.3803, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  41%|████▏     | 194/469 [00:33<00:48,  5.67it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 193/469, Loss: 0.3807, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 195/469 [00:33<00:48,  5.61it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 194/469, Loss: 0.3798, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 196/469 [00:33<00:48,  5.58it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 195/469, Loss: 0.3802, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 197/469 [00:33<00:48,  5.57it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 196/469, Loss: 0.3834, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 198/469 [00:33<00:48,  5.54it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 197/469, Loss: 0.3805, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  42%|████▏     | 199/469 [00:34<00:48,  5.52it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 198/469, Loss: 0.3819, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 200/469 [00:34<00:49,  5.49it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 199/469, Loss: 0.3825, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 201/469 [00:34<00:47,  5.59it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 200/469, Loss: 0.3810, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 202/469 [00:34<00:47,  5.62it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 201/469, Loss: 0.3799, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 203/469 [00:34<00:47,  5.63it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 202/469, Loss: 0.3798, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  43%|████▎     | 204/469 [00:35<00:47,  5.61it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 203/469, Loss: 0.3806, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▎     | 205/469 [00:35<00:47,  5.59it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 204/469, Loss: 0.3815, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▍     | 206/469 [00:35<00:46,  5.61it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 205/469, Loss: 0.3785, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▍     | 207/469 [00:35<00:46,  5.59it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 206/469, Loss: 0.3795, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  44%|████▍     | 208/469 [00:35<00:46,  5.58it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 207/469, Loss: 0.3803, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▍     | 209/469 [00:35<00:46,  5.63it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 208/469, Loss: 0.3791, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▍     | 210/469 [00:36<00:45,  5.65it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 209/469, Loss: 0.3800, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▍     | 211/469 [00:36<00:45,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 210/469, Loss: 0.3810, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▌     | 212/469 [00:36<00:44,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 211/469, Loss: 0.3791, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  45%|████▌     | 213/469 [00:36<00:44,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 212/469, Loss: 0.3783, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▌     | 214/469 [00:36<00:44,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 213/469, Loss: 0.3780, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▌     | 215/469 [00:36<00:44,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 214/469, Loss: 0.3789, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▌     | 216/469 [00:37<00:43,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 215/469, Loss: 0.3803, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▋     | 217/469 [00:37<00:43,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 216/469, Loss: 0.3789, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  46%|████▋     | 218/469 [00:37<00:43,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 217/469, Loss: 0.3792, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 219/469 [00:37<00:43,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 218/469, Loss: 0.3786, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 220/469 [00:37<00:43,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 219/469, Loss: 0.3789, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 221/469 [00:38<00:42,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 220/469, Loss: 0.3786, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  47%|████▋     | 222/469 [00:38<00:42,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 221/469, Loss: 0.3772, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 223/469 [00:38<00:42,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 222/469, Loss: 0.3768, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 224/469 [00:38<00:42,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 223/469, Loss: 0.3756, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 225/469 [00:38<00:42,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 224/469, Loss: 0.3783, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 226/469 [00:38<00:42,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 225/469, Loss: 0.3777, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  48%|████▊     | 227/469 [00:39<00:41,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 226/469, Loss: 0.3778, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▊     | 228/469 [00:39<00:41,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 227/469, Loss: 0.3781, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 229/469 [00:39<00:41,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 228/469, Loss: 0.3769, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 230/469 [00:39<00:40,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 229/469, Loss: 0.3744, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 231/469 [00:39<00:40,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 230/469, Loss: 0.3790, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  49%|████▉     | 232/469 [00:39<00:40,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 231/469, Loss: 0.3782, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|████▉     | 233/469 [00:40<00:40,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 232/469, Loss: 0.3748, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|████▉     | 234/469 [00:40<00:40,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 233/469, Loss: 0.3754, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|█████     | 235/469 [00:40<00:39,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 234/469, Loss: 0.3747, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  50%|█████     | 236/469 [00:40<00:39,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 235/469, Loss: 0.3774, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 237/469 [00:40<00:39,  5.91it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 236/469, Loss: 0.3781, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 238/469 [00:40<00:39,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 237/469, Loss: 0.3756, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 239/469 [00:41<00:39,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 238/469, Loss: 0.3758, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████     | 240/469 [00:41<00:39,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 239/469, Loss: 0.3765, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  51%|█████▏    | 241/469 [00:41<00:39,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 240/469, Loss: 0.3749, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 242/469 [00:41<00:38,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 241/469, Loss: 0.3751, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 243/469 [00:41<00:38,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 242/469, Loss: 0.3769, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 244/469 [00:41<00:38,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 243/469, Loss: 0.3751, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 245/469 [00:42<00:38,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 244/469, Loss: 0.3772, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  52%|█████▏    | 246/469 [00:42<00:38,  5.75it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 245/469, Loss: 0.3758, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 247/469 [00:42<00:38,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 246/469, Loss: 0.3764, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 248/469 [00:42<00:38,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 247/469, Loss: 0.3744, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 249/469 [00:42<00:37,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 248/469, Loss: 0.3767, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  53%|█████▎    | 250/469 [00:42<00:37,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 249/469, Loss: 0.3781, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▎    | 251/469 [00:43<00:37,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 250/469, Loss: 0.3752, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▎    | 252/469 [00:43<00:37,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 251/469, Loss: 0.3735, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▍    | 253/469 [00:43<00:36,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 252/469, Loss: 0.3765, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▍    | 254/469 [00:43<00:36,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 253/469, Loss: 0.3742, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  54%|█████▍    | 255/469 [00:43<00:36,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 254/469, Loss: 0.3759, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▍    | 256/469 [00:44<00:36,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 255/469, Loss: 0.3740, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▍    | 257/469 [00:44<00:36,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 256/469, Loss: 0.3722, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▌    | 258/469 [00:44<00:36,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 257/469, Loss: 0.3729, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▌    | 259/469 [00:44<00:36,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 258/469, Loss: 0.3740, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  55%|█████▌    | 260/469 [00:44<00:36,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 259/469, Loss: 0.3715, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▌    | 261/469 [00:44<00:36,  5.74it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 260/469, Loss: 0.3740, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▌    | 262/469 [00:45<00:36,  5.68it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 261/469, Loss: 0.3751, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▌    | 263/469 [00:45<00:36,  5.70it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 262/469, Loss: 0.3732, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  56%|█████▋    | 264/469 [00:45<00:35,  5.71it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 263/469, Loss: 0.3745, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 265/469 [00:45<00:35,  5.67it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 264/469, Loss: 0.3731, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 266/469 [00:45<00:35,  5.73it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 265/469, Loss: 0.3736, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 267/469 [00:45<00:35,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 266/469, Loss: 0.3744, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 268/469 [00:46<00:34,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 267/469, Loss: 0.3734, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  57%|█████▋    | 269/469 [00:46<00:34,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 268/469, Loss: 0.3719, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 270/469 [00:46<00:33,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 269/469, Loss: 0.3753, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 271/469 [00:46<00:33,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 270/469, Loss: 0.3740, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 272/469 [00:46<00:33,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 271/469, Loss: 0.3728, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 273/469 [00:46<00:33,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 272/469, Loss: 0.3719, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  58%|█████▊    | 274/469 [00:47<00:33,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 273/469, Loss: 0.3730, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▊    | 275/469 [00:47<00:33,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 274/469, Loss: 0.3692, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 276/469 [00:47<00:32,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 275/469, Loss: 0.3698, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 277/469 [00:47<00:32,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 276/469, Loss: 0.3701, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 278/469 [00:47<00:32,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 277/469, Loss: 0.3718, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  59%|█████▉    | 279/469 [00:47<00:32,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 278/469, Loss: 0.3717, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|█████▉    | 280/469 [00:48<00:32,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 279/469, Loss: 0.3721, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|█████▉    | 281/469 [00:48<00:32,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 280/469, Loss: 0.3713, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|██████    | 282/469 [00:48<00:31,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 281/469, Loss: 0.3740, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  60%|██████    | 283/469 [00:48<00:31,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 282/469, Loss: 0.3725, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 284/469 [00:48<00:31,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 283/469, Loss: 0.3693, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 285/469 [00:49<00:31,  5.86it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 284/469, Loss: 0.3699, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 286/469 [00:49<00:31,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 285/469, Loss: 0.3700, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████    | 287/469 [00:49<00:30,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 286/469, Loss: 0.3697, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  61%|██████▏   | 288/469 [00:49<00:30,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 287/469, Loss: 0.3706, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 289/469 [00:49<00:30,  5.89it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 288/469, Loss: 0.3707, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 290/469 [00:49<00:30,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 289/469, Loss: 0.3714, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 291/469 [00:50<00:30,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 290/469, Loss: 0.3719, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 292/469 [00:50<00:30,  5.76it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 291/469, Loss: 0.3726, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  62%|██████▏   | 293/469 [00:50<00:30,  5.78it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 292/469, Loss: 0.3716, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 294/469 [00:50<00:30,  5.77it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 293/469, Loss: 0.3710, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 295/469 [00:50<00:30,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 294/469, Loss: 0.3683, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 296/469 [00:50<00:29,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 295/469, Loss: 0.3684, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  63%|██████▎   | 297/469 [00:51<00:29,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 296/469, Loss: 0.3714, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▎   | 298/469 [00:51<00:29,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 297/469, Loss: 0.3700, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 299/469 [00:51<00:28,  5.88it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 298/469, Loss: 0.3687, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 300/469 [00:51<00:29,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 299/469, Loss: 0.3694, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 301/469 [00:51<00:28,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 300/469, Loss: 0.3673, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  64%|██████▍   | 302/469 [00:51<00:28,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 301/469, Loss: 0.3707, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▍   | 303/469 [00:52<00:28,  5.80it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 302/469, Loss: 0.3685, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▍   | 304/469 [00:52<00:28,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 303/469, Loss: 0.3705, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▌   | 305/469 [00:52<00:28,  5.85it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 304/469, Loss: 0.3685, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▌   | 306/469 [00:52<00:27,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 305/469, Loss: 0.3707, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  65%|██████▌   | 307/469 [00:52<00:27,  5.82it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 306/469, Loss: 0.3685, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▌   | 308/469 [00:52<00:27,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 307/469, Loss: 0.3665, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▌   | 309/469 [00:53<00:27,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 308/469, Loss: 0.3695, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▌   | 310/469 [00:53<00:27,  5.83it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 309/469, Loss: 0.3687, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  66%|██████▋   | 311/469 [00:53<00:27,  5.84it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 310/469, Loss: 0.3673, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 312/469 [00:53<00:27,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 311/469, Loss: 0.3681, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 313/469 [00:53<00:26,  5.79it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 312/469, Loss: 0.3669, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 314/469 [00:53<00:26,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 313/469, Loss: 0.3697, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 315/469 [00:54<00:26,  5.81it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 314/469, Loss: 0.3674, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  67%|██████▋   | 316/469 [00:54<00:26,  5.87it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 315/469, Loss: 0.3672, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 317/469 [00:54<00:25,  5.90it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 316/469, Loss: 0.3676, LR: 0.000000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Training:  68%|██████▊   | 318/469 [00:54<00:25,  5.92it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch 317/469, Loss: 0.3674, LR: 0.000000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cfg = Config()\n",
        "train_model(Tarflow(cfg), cfg)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}